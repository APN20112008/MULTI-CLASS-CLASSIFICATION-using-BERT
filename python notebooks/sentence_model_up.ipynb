{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries and mount gdrive**"
      ],
      "metadata": {
        "id": "_-lQXINF8OmX"
      },
      "id": "_-lQXINF8OmX"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2lerkZ9ClF5",
        "outputId": "7dc8c441-574c-4208-bfde-a476f34f0cdc"
      },
      "id": "W2lerkZ9ClF5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sayLI9focQSw",
        "outputId": "1354dc47-b1db-4fa2-f1a0-a7222784b154"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "torch.__version__"
      ],
      "id": "sayLI9focQSw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check if gpu is available**"
      ],
      "metadata": {
        "id": "pDzws2ZY8d_X"
      },
      "id": "pDzws2ZY8d_X"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.cuda.empty_cache()\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq0SWTfDSmi4",
        "outputId": "8e493c59-4a79-47f8-baaa-12248ffcead2"
      },
      "id": "Eq0SWTfDSmi4",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Datasets**"
      ],
      "metadata": {
        "id": "YfGzY5CU8jMm"
      },
      "id": "YfGzY5CU8jMm"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D62U0vT7cQS2"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/proj/Data/sentences/sentence_train.csv')\n",
        "df_test= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/proj/Data/sentences/sentence_test.csv')"
      ],
      "id": "D62U0vT7cQS2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Dataset**"
      ],
      "metadata": {
        "id": "An2-wSHY8o8O"
      },
      "id": "An2-wSHY8o8O"
    },
    {
      "cell_type": "code",
      "source": [
        "targetList= df_train['label'].unique().tolist()\n",
        "targetList"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWT9JXPyn6Rk",
        "outputId": "e740d5ff-ae71-497b-a442-e190b47a935b"
      },
      "id": "xWT9JXPyn6Rk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vector spaces',\n",
              " 'pos_def_matrices',\n",
              " 'eigenvec_val',\n",
              " 'determinants',\n",
              " 'orthogonality',\n",
              " 'linear_prog',\n",
              " 'gauss elim',\n",
              " 'computations']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "qQrfEVZVcQS2",
        "outputId": "98dc890f-b194-48ad-9839-0930e5fd718d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12121, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-905208e2-b2c8-4f7b-9989-72fa5ce9ee61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>computations</th>\n",
              "      <th>determinants</th>\n",
              "      <th>eigenvec_val</th>\n",
              "      <th>gauss elim</th>\n",
              "      <th>linear_prog</th>\n",
              "      <th>orthogonality</th>\n",
              "      <th>pos_def_matrices</th>\n",
              "      <th>vector spaces</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book begins with the central problem of l...</td>\n",
              "      <td>gauss elim</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>should work and it does: 4 times (x = −1) plus...</td>\n",
              "      <td>gauss elim</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If we stay with determinants (which we don’t p...</td>\n",
              "      <td>gauss elim</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>formula to compute the other unknown, x:</td>\n",
              "      <td>gauss elim</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The idea of elimination is deceptively simple—...</td>\n",
              "      <td>gauss elim</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-905208e2-b2c8-4f7b-9989-72fa5ce9ee61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-905208e2-b2c8-4f7b-9989-72fa5ce9ee61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-905208e2-b2c8-4f7b-9989-72fa5ce9ee61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ... vector spaces\n",
              "0  This book begins with the central problem of l...  ...             0\n",
              "1  should work and it does: 4 times (x = −1) plus...  ...             0\n",
              "2  If we stay with determinants (which we don’t p...  ...             0\n",
              "3           formula to compute the other unknown, x:  ...             0\n",
              "4  The idea of elimination is deceptively simple—...  ...             0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_test = pd.concat([df_test,pd.get_dummies(df_test['label'])], axis=1)\n",
        "df_test.drop(columns='label')\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ],
      "id": "qQrfEVZVcQS2"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "-68hl_GlcQS3",
        "outputId": "4f5e77fd-50e0-4a5b-b33c-723f4641fa7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9983, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-82232f8a-23d7-4e2c-a00a-6bb5d6e5e91a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>computations</th>\n",
              "      <th>determinants</th>\n",
              "      <th>eigenvec_val</th>\n",
              "      <th>gauss elim</th>\n",
              "      <th>linear_prog</th>\n",
              "      <th>orthogonality</th>\n",
              "      <th>pos_def_matrices</th>\n",
              "      <th>vector spaces</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1 3 3 2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The second eigenvalue λ2(A) = 2 is above the l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>matrix Q−1AQ = QTAQ.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i . Stability depends on the eigenvalues:</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rayleigh quotient is the fundamental frequency...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82232f8a-23d7-4e2c-a00a-6bb5d6e5e91a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82232f8a-23d7-4e2c-a00a-6bb5d6e5e91a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82232f8a-23d7-4e2c-a00a-6bb5d6e5e91a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...  vector spaces\n",
              "0                                            1 3 3 2  ...              1\n",
              "1  The second eigenvalue λ2(A) = 2 is above the l...  ...              0\n",
              "2                               matrix Q−1AQ = QTAQ.  ...              0\n",
              "3          i . Stability depends on the eigenvalues:  ...              0\n",
              "4  Rayleigh quotient is the fundamental frequency...  ...              0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_train = pd.concat([df_train,pd.get_dummies(df_train['label'])], axis=1)\n",
        "df_train = df_train.drop(columns='label')\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ],
      "id": "-68hl_GlcQS3"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "Nw8utav_spCA"
      },
      "id": "Nw8utav_spCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a4Mc7KRecQS5"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ],
      "id": "a4Mc7KRecQS5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGtylXumcQS6"
      },
      "outputs": [],
      "source": [
        "tokenizer= BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "id": "uGtylXumcQS6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split dataset into 2 halves to make NN computations less heavy**"
      ],
      "metadata": {
        "id": "gqZcnM578zBe"
      },
      "id": "gqZcnM578zBe"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JZZN97-2cQS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168a3a04-865f-4c2d-e0c6-c6e5104da27c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                text  ...  vector spaces\n",
              " 0  26. If aij is i times j, show that detA = 0. (...  ...              0\n",
              " 1                   by U cannot destroy the scaling.  ...              0\n",
              " 2  Hint: Subtracting the last row from each of th...  ...              0\n",
              " 3  41. A=2∗eye(n)−diag(ones(n−1, 1),1)−diag(ones(...  ...              0\n",
              " 4  optimal λ and µ. In the exercises, we stay wit...  ...              0\n",
              " \n",
              " [5 rows x 9 columns],\n",
              "                                                 text  ...  vector spaces\n",
              " 0  ak and bk. From this inﬁnite sequence of sines...  ...              0\n",
              " 1  that a zero can appear in a pivot position, ev...  ...              0\n",
              " 2              13. Apply the Gram-Schmidt process to  ...              0\n",
              " 3                                   A changes to ATA  ...              0\n",
              " 4  The general case is the same. We “solve” ax = ...  ...              0\n",
              " \n",
              " [5 rows x 9 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_train1=df_train.sample(frac=0.5, random_state= 200).reset_index(drop=True)\n",
        "page_df= df_train.drop(df_train1.index).reset_index(drop=True)\n",
        "df_train= df_train1\n",
        "page_df.head(), df_train.head()"
      ],
      "id": "JZZN97-2cQS6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic parameters for training a deep learning model**"
      ],
      "metadata": {
        "id": "7Z8uncjo9EEi"
      },
      "id": "7Z8uncjo9EEi"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "voXT45gOcQS8"
      },
      "outputs": [],
      "source": [
        "MAX_LEN= 256\n",
        "BATCH_SIZE= 16\n",
        "EPOCHS= 4\n",
        "LR= 1e-4"
      ],
      "id": "voXT45gOcQS8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset class to get text encodings**"
      ],
      "metadata": {
        "id": "P_TY1hGk9LPG"
      },
      "id": "P_TY1hGk9LPG"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cQgMHqzfcQS9"
      },
      "outputs": [],
      "source": [
        "class myDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,df, tokenizer, max_len):\n",
        "        self.df = df\n",
        "        self.tokenizer= tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.text= df['text']\n",
        "        self.targets = self.df[targetList].values\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        text= str(self.text[index])\n",
        "        text=  \" \".join(text.split())\n",
        "        \n",
        "        inputs= self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids= True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors= 'pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids':inputs['input_ids'].flatten(),\n",
        "            'attention_mask':inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids':inputs['token_type_ids'].flatten(),\n",
        "            'targets':torch.FloatTensor(self.targets[index])\n",
        "        }\n"
      ],
      "id": "cQgMHqzfcQS9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split current training set into train and validation sets**"
      ],
      "metadata": {
        "id": "OH3MQKeJ9awA"
      },
      "id": "OH3MQKeJ9awA"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udcGroaAcQS9",
        "outputId": "31d68055-af27-401c-ec5e-a06ccf569ccb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3994, 9), (998, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_df= df_train.sample(frac=0.8,random_state=200).reset_index(drop=True)\n",
        "val_df= df_train.drop(train_df.index).reset_index(drop=True)\n",
        "train_df.shape, val_df.shape"
      ],
      "id": "udcGroaAcQS9"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "o7QlLJbQcQS-"
      },
      "outputs": [],
      "source": [
        "train_dataset=myDataset(train_df,tokenizer, MAX_LEN)\n",
        "val_dataset = myDataset(val_df,tokenizer,MAX_LEN)"
      ],
      "id": "o7QlLJbQcQS-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare DataLoader objects**"
      ],
      "metadata": {
        "id": "YNNEpthd9gau"
      },
      "id": "YNNEpthd9gau"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8QYzChFzcQS-"
      },
      "outputs": [],
      "source": [
        "trainLoader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers= 0 \n",
        "    )\n",
        "valLoader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers= 0 \n",
        "    )"
      ],
      "id": "8QYzChFzcQS-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and save checkpoints in case system crashes or we need to use model parameters somewhere else**"
      ],
      "metadata": {
        "id": "4rwBlD-q9lmn"
      },
      "id": "4rwBlD-q9lmn"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C6VDsDjFcQS_"
      },
      "outputs": [],
      "source": [
        "def load_ckp(ckpt_path,model,optimizer):\n",
        "    checkpoint= torch.load(ckpt_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    valid_loss_min= checkpoint['valid_loss_min']\n",
        "    return model, optimizer, checkpoint['epoch'],valid_loss_min\n",
        "def save_ckp(state, is_best, ckpt_path,best_model_path):\n",
        "    torch.save(state, ckpt_path)\n",
        "    if is_best:\n",
        "        best_path = best_model_path\n",
        "        shutil.copyfile(ckpt_path,best_path)"
      ],
      "id": "C6VDsDjFcQS_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT CLASS: Describes how model will behave**\n",
        "_Bert base computations->dropout layer->linear layer_ "
      ],
      "metadata": {
        "id": "M8rsjPa09ulu"
      },
      "id": "M8rsjPa09ulu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXxTqp-xcQS_"
      },
      "outputs": [],
      "source": [
        "class BERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTModel,self).__init__()\n",
        "        self.bert= BertModel.from_pretrained(\"bert-base-uncased\", return_dict= True)\n",
        "        self.dropout = nn.Dropout(0.6) \n",
        "        self.linear =nn.Linear(768,8)\n",
        "    def forward(self, input_ids,attention_mask,token_type_ids):\n",
        "        output = self.bert(input_ids,attention_mask,token_type_ids)\n",
        "        outputDropout= self.dropout(output.pooler_output)\n",
        "        output= self.linear(outputDropout)\n",
        "        return output\n",
        "model = BERTModel()\n",
        "model.to(device)"
      ],
      "id": "BXxTqp-xcQS_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Loss function**\n",
        "\n",
        "_Model.parameters() consists of model weights and biases_"
      ],
      "metadata": {
        "id": "hL1JD-Bw-Q1_"
      },
      "id": "hL1JD-Bw-Q1_"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "k088yFo8cQTA"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs,targets)\n",
        "def accuracy(output,targets):\n",
        "  final_output = torch.sigmoid(output).cpu().detach().numpy()\n",
        "  return np.sum( np.argmax(targets.cpu().numpy(),axis=1) == np.argmax(final_output, axis=1) ) / BATCH_SIZE *100\n",
        "optimizer= torch.optim.Adam(params=model.parameters(),lr=LR)"
      ],
      "id": "k088yFo8cQTA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define train function. Define fine-tuning procedure step by step**"
      ],
      "metadata": {
        "id": "dUKTOSLf-g0Q"
      },
      "id": "dUKTOSLf-g0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs, trainLoader,valLoader,model,optimizer,ckpt_path,best_model_path,val_loss_min):\n",
        "    for epoch in range(1, epochs+1):\n",
        "        print(\"epoch[{}]\".format(epoch))\n",
        "        train_loss= 0\n",
        "        val_loss= 0\n",
        "        for index, batch in enumerate(trainLoader):\n",
        "            input_ids= batch['input_ids'].to(device, dtype= torch.long)\n",
        "            attention_mask = batch['attention_mask'].to(device, dtype= torch.long)\n",
        "            token_type_ids= batch['token_type_ids'].to(device, dtype= torch.long)\n",
        "            targets = batch['targets'].to(device, dtype= torch.float)\n",
        "\n",
        "            output= model(input_ids, attention_mask, token_type_ids)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss= loss_fn(output,targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_acc= accuracy(output,targets)\n",
        "            train_loss=train_loss + ((1/(index+1))*(loss.item()-train_loss))\n",
        "            print(\"TRAIN BATCH {}/{}====>train loss[{:.8f}] | train accuracy[{:.8f}%]\".format(index+1,len(trainLoader) , train_loss, train_acc ))\n",
        "            #train_lossList+=[train_loss]\n",
        "            #train_accList+=[train_acc]\n",
        "        model.eval() \n",
        "        with torch.no_grad():\n",
        "            for index, batch in enumerate(valLoader):\n",
        "                print(\"validation batch index:{}/{}\".format(index,len(valLoader)))\n",
        "                input_ids= batch['input_ids'].to(device, dtype= torch.long)\n",
        "                attention_mask = batch['attention_mask'].to(device, dtype= torch.long)\n",
        "                token_type_ids= batch['token_type_ids'].to(device, dtype= torch.long)\n",
        "                targets = batch['targets'].to(device, dtype= torch.float)\n",
        "                \n",
        "                output =model(input_ids,attention_mask,token_type_ids)\n",
        "                val_acc= accuracy(output,targets)\n",
        "                loss= loss_fn(output,targets)\n",
        "                val_loss= (val_loss + (1/(index+1))*(loss.item()-val_loss))\n",
        "                print(\"VALIDATION BATCH {}/{}====>val loss[{:.8f}] | val accuracy[{:.8f}%]\".format(index+1,len(valLoader) , val_loss, val_acc ))\n",
        "                #val_lossList+=[val_loss]\n",
        "                #val_accList+=[val_acc]\n",
        "        checkpoint ={\n",
        "            'epoch': epoch+1,\n",
        "            'valid_loss_min':val_loss,\n",
        "            'state_dict':model.state_dict(),\n",
        "            'optimizer':optimizer.state_dict()\n",
        "        }\n",
        "        save_ckp(checkpoint,False,ckpt_path,best_model_path)\n",
        "\n",
        "        if val_loss < val_loss_min:\n",
        "          print(\"previous Val_loss_min={:.8f}; new val_loss_min={:.8f}\".format(val_loss_min, val_loss))\n",
        "          save_ckp(checkpoint, True, ckpt_path, best_model_path)\n",
        "          print(\"SAVED\")\n",
        "          val_loss_min = val_loss\n",
        "        print(\"epoch {} end\".format(epoch))\n",
        "    return model"
      ],
      "metadata": {
        "id": "ASXE6XlPAraR"
      },
      "id": "ASXE6XlPAraR",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train 1st half of dataset**"
      ],
      "metadata": {
        "id": "BBszqGmj-tdC"
      },
      "id": "BBszqGmj-tdC"
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/Colab Notebooks/proj/Data/sentences/curr_path\"\n",
        "best_model_path = \"/content/drive/MyDrive/Colab Notebooks/proj/Data/sentences/best.pt\""
      ],
      "metadata": {
        "id": "FEBe8RiAga0C"
      },
      "id": "FEBe8RiAga0C",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE7hvW4AcQTB",
        "outputId": "b16843a1-363c-40e7-cfa2-817e857f8e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch[1]\n",
            "TRAIN BATCH 1/250====>train loss[0.74241090] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.71333539] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.69315662] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.66752519] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.63965445] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.61854233] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.59202537] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.57190254] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.55311090] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.53944784] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.52685070] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.51544100] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.50590301] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.50003445] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.49284936] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.48596295] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.48028616] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.47591320] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.47166574] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.46638793] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.46221378] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.45720377] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.45260664] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.44961526] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.44769506] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.44485370] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.44188319] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.43949913] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.43653789] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.43448858] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.43189954] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.43147875] | train accuracy[0.00000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.42985770] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.42800126] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.42645485] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.42410714] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.42279539] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.42136501] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.42031741] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.41844132] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.41721934] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.41693752] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.41556318] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.41464357] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.41390426] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.41279856] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.41140502] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.41039420] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.40957606] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.40912227] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.40900787] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.40804644] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.40740391] | train accuracy[0.00000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.40664567] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.40556262] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.40507204] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.40468668] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.40415268] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.40402789] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.40261918] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.40186354] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.40169419] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.40113658] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.40101497] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.40140155] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.40049810] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.40020523] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.39977924] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.39952355] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.39913821] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.39900311] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.39884542] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.39853615] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.39803584] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.39736108] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.39722423] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.39699699] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.39665226] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.39666075] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.39652059] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.39611041] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.39588672] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.39580899] | train accuracy[0.00000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.39588666] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.39544079] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.39518136] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.39497596] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.39458312] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.39411448] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.39370166] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.39355426] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.39349392] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.39340660] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.39331373] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.39329230] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.39319408] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.39319576] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.39280497] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.39253943] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.39232524] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.39224406] | train accuracy[0.00000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.39210312] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.39187905] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.39154059] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.39109045] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.39084727] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.39054417] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.39033851] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.39012675] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.38998665] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.38986723] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.38939647] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.38913061] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.38875625] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.38875089] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.38860351] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.38821235] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.38838774] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.38796797] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.38747530] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.38725122] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.38672478] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.38637869] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.38654078] | train accuracy[6.25000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.38604733] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.38599609] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.38567957] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.38542073] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.38518210] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.38485386] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.38456976] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.38388206] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.38385233] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.38369095] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.38341638] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.38309215] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.38293219] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.38256042] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.38226535] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.38225791] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.38210043] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.38149644] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.38132672] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.38112935] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.38062204] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.38053275] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.37994735] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.37966318] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.37919282] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.37888805] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.37842660] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.37778190] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.37774718] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.37751907] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.37679425] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.37653060] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.37640195] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.37624584] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.37605169] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.37581116] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.37540549] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.37527265] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.37546471] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.37532950] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.37513276] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.37501101] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.37486986] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.37449009] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.37442857] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.37425622] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.37438116] | train accuracy[12.50000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.37411824] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.37380636] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.37337859] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.37318594] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.37310874] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.37287719] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.37234227] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.37193465] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.37157359] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.37140472] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.37092580] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.37081366] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.37043387] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.36984738] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.36950330] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.36919631] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.36910799] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.36887460] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.36848709] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.36828931] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.36784866] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.36761464] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.36722896] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.36701120] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.36676881] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.36615910] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.36581214] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.36547128] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.36557037] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.36517171] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.36507812] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.36466324] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.36430026] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.36398030] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.36397101] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.36343089] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.36328307] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.36289227] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.36257233] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.36233511] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.36223082] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.36181170] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.36143657] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.36103701] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.36084666] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.36070116] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.36067204] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.36021724] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.35975351] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.35955983] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.35927149] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.35912403] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.35886481] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.35847470] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.35804528] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.35776549] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.35744840] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.35724879] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.35685697] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.35673959] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.35664608] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.35665883] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.35616629] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.35615890] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.35579115] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.35560656] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.35527021] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.35497219] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.35459967] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.35427412] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.35424391] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.35392219] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.35364097] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.35344509] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.35360740] | train accuracy[18.75000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.35337776] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.35315388] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.35317148] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.35304645] | train accuracy[25.00000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.24036688] | val accuracy[62.50000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.22772221] | val accuracy[87.50000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.25039297] | val accuracy[56.25000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.25340838] | val accuracy[56.25000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.26219576] | val accuracy[50.00000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.26767871] | val accuracy[50.00000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.27528440] | val accuracy[43.75000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.27991223] | val accuracy[37.50000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.28181245] | val accuracy[50.00000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.28134614] | val accuracy[56.25000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.27656735] | val accuracy[68.75000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.27797182] | val accuracy[43.75000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.27666575] | val accuracy[50.00000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.27506335] | val accuracy[62.50000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.27389116] | val accuracy[56.25000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.27039829] | val accuracy[75.00000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.26876479] | val accuracy[62.50000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.26861444] | val accuracy[43.75000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.26538860] | val accuracy[75.00000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.26498511] | val accuracy[50.00000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.26414129] | val accuracy[68.75000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.26278612] | val accuracy[62.50000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.26095248] | val accuracy[75.00000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.26181769] | val accuracy[56.25000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.26056345] | val accuracy[68.75000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.26071506] | val accuracy[62.50000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.26231720] | val accuracy[37.50000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.26142838] | val accuracy[62.50000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.26315394] | val accuracy[50.00000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.26219887] | val accuracy[68.75000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.26301696] | val accuracy[56.25000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.26382098] | val accuracy[43.75000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.26467631] | val accuracy[50.00000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.26381670] | val accuracy[68.75000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.26351333] | val accuracy[56.25000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.26328967] | val accuracy[68.75000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.26316058] | val accuracy[56.25000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.26266580] | val accuracy[62.50000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.26356802] | val accuracy[50.00000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.26468132] | val accuracy[37.50000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.26502720] | val accuracy[43.75000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.26455133] | val accuracy[68.75000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.26406501] | val accuracy[68.75000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.26614844] | val accuracy[31.25000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.26520453] | val accuracy[75.00000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.26624332] | val accuracy[43.75000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.26755492] | val accuracy[43.75000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.26796659] | val accuracy[37.50000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.26920328] | val accuracy[43.75000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.26848077] | val accuracy[62.50000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.26893403] | val accuracy[43.75000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.26819738] | val accuracy[68.75000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.26900712] | val accuracy[37.50000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.26930793] | val accuracy[50.00000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.26872796] | val accuracy[68.75000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.26945144] | val accuracy[50.00000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.26907134] | val accuracy[68.75000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.26891617] | val accuracy[50.00000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.26876430] | val accuracy[56.25000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.26821182] | val accuracy[62.50000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.26801291] | val accuracy[56.25000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.26799710] | val accuracy[43.75000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.26740507] | val accuracy[18.75000000%]\n",
            "previous Val_loss_min=inf; new val_loss_min=0.26740507\n",
            "SAVED\n",
            "epoch 1 end\n",
            "epoch[2]\n",
            "TRAIN BATCH 1/250====>train loss[0.25978062] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.29012650] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.27852843] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.27462524] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.27497097] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.27198180] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.26625158] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.26703698] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.26766443] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.26898925] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.27117454] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.26800562] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.26473786] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.26558187] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.26630111] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.26383244] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.25999592] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.25943885] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.25738217] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.25794250] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.26271863] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.26388470] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.26182269] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.26116391] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.25948711] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.26086590] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.25946507] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.26288310] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.26427483] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.26426448] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.26457627] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.26286039] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.26420230] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.26412609] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.26322992] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.26295265] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.26345778] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.26276776] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.26305211] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.26412541] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.26249600] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.26245312] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.26357018] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.26367904] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.26364099] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.26223440] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.26138390] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.26197195] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.26072642] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.26218215] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.26119746] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.26117634] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.26038009] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.26058447] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.26001026] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.26068311] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.25988177] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.25859017] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.25995991] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.26000080] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.25951979] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.26030573] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.26056998] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.26081255] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.25955119] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.25867947] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.25876743] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.25903031] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.26007150] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.25922231] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.25833485] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.25838672] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.25886749] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.25840029] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.25838578] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.25809042] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.25764782] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.25737674] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.25676451] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.25667156] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.25719331] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.25691300] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.25600538] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.25613391] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.25514872] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.25517615] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.25440259] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.25452763] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.25543928] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.25510458] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.25572015] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.25570051] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.25564604] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.25685640] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.25732588] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.25694097] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.25643083] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.25618911] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.25591327] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.25526657] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.25546152] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.25480122] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.25542138] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.25559833] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.25561024] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.25544162] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.25539921] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.25514401] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.25528938] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.25567075] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.25488842] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.25495098] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.25443164] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.25455574] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.25443535] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.25421876] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.25435899] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.25478256] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.25476742] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.25400704] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.25397566] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.25390313] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.25423456] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.25444682] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.25465606] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.25419927] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.25412868] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.25404689] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.25389217] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.25364893] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.25414732] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.25367486] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.25374450] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.25351457] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.25366441] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.25301955] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.25293983] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.25300801] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.25276362] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.25258011] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.25301301] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.25356091] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.25335132] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.25309621] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.25270131] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.25271428] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.25238549] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.25208985] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.25198782] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.25197946] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.25199641] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.25178344] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.25174580] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.25190470] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.25185347] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.25150556] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.25117434] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.25065825] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.25068352] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.25107718] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.25119183] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.25089275] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.25113809] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.25141254] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.25133765] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.25154769] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.25135190] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.25141619] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.25166655] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.25154114] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.25128573] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.25146664] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.25156374] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.25144668] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.25148020] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.25127166] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.25132552] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.25106431] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.25202319] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.25179676] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.25127226] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.25118113] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.25068596] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.25056932] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.25071725] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.25046676] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.25071235] | train accuracy[25.00000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.25045261] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.25028787] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.24991830] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.24991481] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.24989729] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.25016062] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.25056468] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.25053918] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.25036103] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.25019817] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.25036229] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.25001815] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.25017299] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.25021267] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.25026821] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.25015852] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.25012670] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.25027329] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.25037120] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.25012236] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.25020969] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.24967098] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.24967539] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.24935031] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.24960945] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.24918279] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.24900630] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.24844007] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.24810766] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.24776992] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.24744305] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.24730489] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.24709971] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.24704610] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.24678024] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.24645845] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.24635589] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.24622518] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.24643162] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.24603128] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.24607380] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.24579238] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.24541824] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.24556546] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.24555288] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.24550898] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.24549934] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.24570001] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.24587484] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.24580295] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.24575139] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.24573850] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.24578382] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.24580912] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.24576987] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.24542219] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.24522213] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.24502733] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.24523569] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.24499661] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.24487669] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.24508472] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.24513353] | train accuracy[37.50000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.19726625] | val accuracy[68.75000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.18309630] | val accuracy[87.50000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.20018870] | val accuracy[56.25000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.19354928] | val accuracy[75.00000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.19901894] | val accuracy[56.25000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.20797404] | val accuracy[56.25000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.21648654] | val accuracy[56.25000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.21109798] | val accuracy[81.25000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.21494590] | val accuracy[56.25000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.21082781] | val accuracy[75.00000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.20449451] | val accuracy[81.25000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.20061730] | val accuracy[75.00000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.19838177] | val accuracy[75.00000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.19733982] | val accuracy[81.25000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.19523417] | val accuracy[81.25000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.19144187] | val accuracy[87.50000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.19240084] | val accuracy[68.75000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.19242781] | val accuracy[75.00000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.18869543] | val accuracy[87.50000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.18617765] | val accuracy[87.50000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.18840499] | val accuracy[62.50000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.18907055] | val accuracy[68.75000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.18620725] | val accuracy[87.50000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.18875778] | val accuracy[50.00000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.18909515] | val accuracy[75.00000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.18955504] | val accuracy[68.75000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.19059299] | val accuracy[62.50000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.18920006] | val accuracy[81.25000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.19078404] | val accuracy[56.25000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.19000590] | val accuracy[81.25000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.18977161] | val accuracy[75.00000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.18827454] | val accuracy[81.25000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.18668292] | val accuracy[93.75000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.18463894] | val accuracy[87.50000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.18478509] | val accuracy[62.50000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.18708039] | val accuracy[50.00000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.18804588] | val accuracy[62.50000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.18765849] | val accuracy[75.00000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.18761903] | val accuracy[75.00000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.18723832] | val accuracy[75.00000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.18701664] | val accuracy[75.00000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.18653504] | val accuracy[75.00000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.18591930] | val accuracy[75.00000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.18779185] | val accuracy[37.50000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.18637576] | val accuracy[87.50000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.18699649] | val accuracy[68.75000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.18769245] | val accuracy[68.75000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.18770966] | val accuracy[68.75000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.18806240] | val accuracy[68.75000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.18745935] | val accuracy[81.25000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.18738100] | val accuracy[75.00000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.18671910] | val accuracy[75.00000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.18723322] | val accuracy[68.75000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.18774484] | val accuracy[62.50000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.18720568] | val accuracy[87.50000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.18847992] | val accuracy[62.50000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.18835820] | val accuracy[75.00000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.18748186] | val accuracy[81.25000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.18686791] | val accuracy[81.25000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.18691495] | val accuracy[68.75000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.18712268] | val accuracy[75.00000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.18659179] | val accuracy[81.25000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.18717551] | val accuracy[25.00000000%]\n",
            "previous Val_loss_min=0.26740507; new val_loss_min=0.18717551\n",
            "SAVED\n",
            "epoch 2 end\n",
            "epoch[3]\n",
            "TRAIN BATCH 1/250====>train loss[0.09310310] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.10141789] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.13637339] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.16390541] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.15450661] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.14959334] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.14690164] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.14672322] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.14540410] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.14901696] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.15005337] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.14648657] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.14529380] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.14155587] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.14025139] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.13782819] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.14330376] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.14592807] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.14851152] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.14905643] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.15091216] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.15331494] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.15353546] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.15533151] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.15698985] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.15603114] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.15290364] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.15110257] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.14991225] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.14800821] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.14845753] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.14932199] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.14826497] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.14848970] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.14880709] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.14751376] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.14603391] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.14721962] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.14683034] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.14813499] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.14814100] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.14821035] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.14882074] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.15018096] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.14958973] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.15269542] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.15376421] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.15263022] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.15378201] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.15369562] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.15577905] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.15638082] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.15683133] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.15578369] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.15655269] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.15537795] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.15510958] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.15698046] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.15927576] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.15979813] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.16292521] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.16369375] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.16427986] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.16493135] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.16408538] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.16472088] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.16451898] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.16544843] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.16621369] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.16562193] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.16654201] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.16638812] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.16664868] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.16719352] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.16798561] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.16745851] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.16702057] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.16722543] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.16709271] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.16694091] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.16637249] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.16663025] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.16613172] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.16648234] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.16693726] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.16716801] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.16715764] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.16709781] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.16805231] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.16835713] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.16942643] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.16922530] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.16937508] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.16953381] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.17033594] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.17076320] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.17086319] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.17207572] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.17294751] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.17252452] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.17267501] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.17347623] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.17360065] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.17338426] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.17314375] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.17312402] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.17279421] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.17305125] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.17272000] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.17256922] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.17194541] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.17208293] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.17155192] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.17134423] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.17099255] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.17084576] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.17133565] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.17132827] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.17122522] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.17045307] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.17086083] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.17088454] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.17089197] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.17102569] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.17134107] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.17106256] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.17089242] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.17029077] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.17111551] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.17082435] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.17097023] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.17060754] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.17042653] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.17096686] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.17041534] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.17072522] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.17098447] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.17205693] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.17180248] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.17188921] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.17266495] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.17221637] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.17180236] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.17182177] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.17218773] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.17172288] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.17161943] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.17186997] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.17205005] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.17242935] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.17251911] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.17202768] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.17249830] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.17198479] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.17240206] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.17197230] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.17174342] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.17189354] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.17137713] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.17159088] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.17193122] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.17217188] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.17226675] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.17263425] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.17284697] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.17271062] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.17264946] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.17241680] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.17205505] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.17212081] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.17206462] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.17198655] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.17170763] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.17139465] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.17156407] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.17210673] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.17231429] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.17193329] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.17211149] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.17183572] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.17218382] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.17240845] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.17240576] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.17235990] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.17206664] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.17231996] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.17254043] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.17257868] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.17216462] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.17252796] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.17241910] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.17252069] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.17241153] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.17281644] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.17257211] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.17227269] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.17231609] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.17272648] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.17223045] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.17233486] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.17252534] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.17272416] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.17246600] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.17237274] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.17188332] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.17209078] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.17214310] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.17222455] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.17209578] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.17188393] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.17157603] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.17131628] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.17117548] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.17117911] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.17117090] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.17098270] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.17106517] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.17135165] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.17137174] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.17131491] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.17159818] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.17173940] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.17171458] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.17151226] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.17156422] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.17151894] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.17182031] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.17184655] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.17209877] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.17208423] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.17194693] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.17221368] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.17191366] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.17211163] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.17218582] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.17232516] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.17213901] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.17224833] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.17272028] | train accuracy[31.25000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.17245086] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.17254000] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.17281387] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.17253075] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.17220634] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.17222155] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.17199395] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.17231713] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.17236703] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.17238128] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.17245286] | train accuracy[37.50000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.18056716] | val accuracy[75.00000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.14260984] | val accuracy[87.50000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.15368600] | val accuracy[87.50000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.14510421] | val accuracy[87.50000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.14204641] | val accuracy[75.00000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.14239329] | val accuracy[81.25000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.15199969] | val accuracy[62.50000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.15169468] | val accuracy[75.00000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.15292903] | val accuracy[75.00000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.15592501] | val accuracy[75.00000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.15415426] | val accuracy[87.50000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.15483140] | val accuracy[75.00000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.15343485] | val accuracy[75.00000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.14918236] | val accuracy[87.50000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.14492692] | val accuracy[93.75000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.14214218] | val accuracy[87.50000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.14393030] | val accuracy[81.25000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.14719407] | val accuracy[75.00000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.14188879] | val accuracy[100.00000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.14167516] | val accuracy[75.00000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.14081411] | val accuracy[81.25000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.13999789] | val accuracy[81.25000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.13911719] | val accuracy[93.75000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.14026105] | val accuracy[68.75000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.13840182] | val accuracy[87.50000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.13733071] | val accuracy[87.50000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.13708916] | val accuracy[81.25000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.13564191] | val accuracy[93.75000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.13436189] | val accuracy[93.75000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.13482386] | val accuracy[81.25000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.13441905] | val accuracy[87.50000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.13348300] | val accuracy[87.50000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.13313715] | val accuracy[81.25000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.13216024] | val accuracy[87.50000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.13202899] | val accuracy[81.25000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.13388551] | val accuracy[75.00000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.13600277] | val accuracy[68.75000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.13647110] | val accuracy[81.25000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.13658263] | val accuracy[87.50000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.13611016] | val accuracy[81.25000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.13537979] | val accuracy[81.25000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.13453129] | val accuracy[87.50000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.13415399] | val accuracy[87.50000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.13463824] | val accuracy[75.00000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.13414064] | val accuracy[81.25000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.13578876] | val accuracy[68.75000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.13475611] | val accuracy[93.75000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.13577646] | val accuracy[68.75000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.13485033] | val accuracy[87.50000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.13361162] | val accuracy[100.00000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.13239854] | val accuracy[100.00000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.13192773] | val accuracy[81.25000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.13222554] | val accuracy[81.25000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.13196512] | val accuracy[87.50000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.13223558] | val accuracy[87.50000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.13272053] | val accuracy[81.25000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.13194012] | val accuracy[87.50000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.13208295] | val accuracy[81.25000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.13294551] | val accuracy[75.00000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.13194303] | val accuracy[93.75000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.13194448] | val accuracy[87.50000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.13117067] | val accuracy[87.50000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.13186502] | val accuracy[25.00000000%]\n",
            "previous Val_loss_min=0.18717551; new val_loss_min=0.13186502\n",
            "SAVED\n",
            "epoch 3 end\n",
            "epoch[4]\n",
            "TRAIN BATCH 1/250====>train loss[0.16342835] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.16186763] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.12770940] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.11427353] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.11459045] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.11580132] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.11309411] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.12429160] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.11988147] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.12027060] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.11765041] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.11698254] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.11885423] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.11716123] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.11465622] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.11034826] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.11102483] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.11103444] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.11132088] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.11488547] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.11549288] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.11392236] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.11561640] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.11577136] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.11544537] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.11597064] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.11648326] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.12045251] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.11952968] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.12454123] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.12476129] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.12403894] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.12250026] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.12224764] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.12079958] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.12144485] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.11952602] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.11852926] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.11856076] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.11809664] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.11794361] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.11678303] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.11635663] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.11685422] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.11512063] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.11553277] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.11667033] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.11707916] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.11853827] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.11761451] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.11681111] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.11654360] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.11710026] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.11748713] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.11858792] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.11748573] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.11733106] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.11676368] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.11673908] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.11584309] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.11557703] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.11434768] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.11408533] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.11361425] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.11313207] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.11295163] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.11369364] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.11363335] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.11456518] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.11412681] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.11505340] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.11516705] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.11434045] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.11358461] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.11305108] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.11290394] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.11261797] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.11461188] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.11418220] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.11383251] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.11437686] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.11460781] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.11481710] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.11438547] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.11498925] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.11434726] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.11417545] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.11395056] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.11329930] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.11333102] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.11305765] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.11246602] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.11330981] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.11324108] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.11257113] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.11258113] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.11332181] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.11313107] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.11307204] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.11252315] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.11303351] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.11316835] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.11287609] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.11271072] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.11245338] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.11218569] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.11258190] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.11247260] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.11204528] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.11208202] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.11223825] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.11186679] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.11111855] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.11089559] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.11045260] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.11031590] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.10974236] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.10966285] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.10967961] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.10968662] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.10967169] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.10957695] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.10980867] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.11014870] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.10969295] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.10986389] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.10978491] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.11040895] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.11052459] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.11066231] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.11212716] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.11206225] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.11213021] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.11208195] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.11207791] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.11198836] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.11232058] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.11227040] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.11213447] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.11193837] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.11216857] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.11208775] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.11263712] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.11272168] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.11249723] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.11264956] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.11289059] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.11277069] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.11266809] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.11363448] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.11358884] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.11360781] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.11334868] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.11329567] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.11358659] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.11391868] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.11384855] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.11380841] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.11389508] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.11385665] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.11370998] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.11384092] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.11392816] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.11389095] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.11374626] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.11395476] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.11375213] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.11349846] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.11322570] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.11319515] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.11293282] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.11273824] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.11329033] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.11315698] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.11319772] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.11338254] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.11299666] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.11301375] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.11336878] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.11327919] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.11314334] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.11343506] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.11391347] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.11385852] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.11354376] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.11367342] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.11328262] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.11344053] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.11321069] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.11299692] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.11298395] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.11301119] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.11311803] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.11319669] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.11327214] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.11345120] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.11321816] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.11286880] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.11296081] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.11273977] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.11265341] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.11253638] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.11258083] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.11256481] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.11246674] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.11274623] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.11278781] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.11261403] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.11272665] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.11325516] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.11314342] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.11337724] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.11338817] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.11422894] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.11467822] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.11447102] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.11462312] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.11455895] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.11437718] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.11462087] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.11458830] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.11451430] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.11452902] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.11426695] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.11408288] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.11419285] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.11413977] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.11384645] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.11375786] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.11345423] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.11365340] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.11410998] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.11428341] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.11404103] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.11439623] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.11508207] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.11473716] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.11470273] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.11499385] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.11467869] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.11450833] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.11424391] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.11418759] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.11422476] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.11436332] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.11475320] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.11479144] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.11485482] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.11463286] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.11431318] | train accuracy[62.50000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.16145900] | val accuracy[81.25000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.11527661] | val accuracy[93.75000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.12241668] | val accuracy[87.50000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.12164470] | val accuracy[81.25000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.11827306] | val accuracy[81.25000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.12527199] | val accuracy[81.25000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.12351104] | val accuracy[87.50000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.12174598] | val accuracy[87.50000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.12702712] | val accuracy[81.25000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.12946349] | val accuracy[81.25000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.12622716] | val accuracy[93.75000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.12331100] | val accuracy[93.75000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.12607998] | val accuracy[68.75000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.12310218] | val accuracy[93.75000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.12069026] | val accuracy[93.75000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.11738298] | val accuracy[93.75000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.11981877] | val accuracy[75.00000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.12161089] | val accuracy[81.25000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.11951837] | val accuracy[93.75000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.11863803] | val accuracy[81.25000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.11853032] | val accuracy[87.50000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.11847761] | val accuracy[87.50000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.11578297] | val accuracy[93.75000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.11729565] | val accuracy[81.25000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.11557992] | val accuracy[87.50000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.11498318] | val accuracy[81.25000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.11528925] | val accuracy[75.00000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.11420900] | val accuracy[87.50000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.11365968] | val accuracy[81.25000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.11289441] | val accuracy[93.75000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.11296653] | val accuracy[87.50000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.11053731] | val accuracy[100.00000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.10978793] | val accuracy[93.75000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.10750765] | val accuracy[100.00000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.10834500] | val accuracy[81.25000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.11043431] | val accuracy[75.00000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.11118283] | val accuracy[75.00000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.11143116] | val accuracy[81.25000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.11187192] | val accuracy[81.25000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.11231630] | val accuracy[81.25000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.11141816] | val accuracy[87.50000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.11050874] | val accuracy[93.75000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.11029764] | val accuracy[87.50000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.11338478] | val accuracy[56.25000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.11211931] | val accuracy[93.75000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.11204474] | val accuracy[81.25000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.11099371] | val accuracy[93.75000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.10996827] | val accuracy[100.00000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.11015165] | val accuracy[87.50000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.10898385] | val accuracy[93.75000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.10760414] | val accuracy[100.00000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.10658745] | val accuracy[100.00000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.10744439] | val accuracy[81.25000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.10712823] | val accuracy[87.50000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.10721031] | val accuracy[81.25000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.10793121] | val accuracy[75.00000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.10757882] | val accuracy[87.50000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.10731091] | val accuracy[87.50000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.10769607] | val accuracy[81.25000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.10712368] | val accuracy[93.75000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.10708793] | val accuracy[87.50000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.10636731] | val accuracy[87.50000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.10706023] | val accuracy[31.25000000%]\n",
            "previous Val_loss_min=0.13186502; new val_loss_min=0.10706023\n",
            "SAVED\n",
            "epoch 4 end\n"
          ]
        }
      ],
      "source": [
        "trained_model=train_model(EPOCHS,trainLoader,valLoader,model, optimizer,ckpt_path,best_model_path,np.Inf)"
      ],
      "id": "UE7hvW4AcQTB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train 2nd half of dataset**"
      ],
      "metadata": {
        "id": "hltd3dGC-yfH"
      },
      "id": "hltd3dGC-yfH"
    },
    {
      "cell_type": "code",
      "source": [
        "train_df2= page_df.sample(frac=0.8,random_state=200).reset_index(drop=True)\n",
        "val_df2= page_df.drop(train_df2.index).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "FT1vlCAlLGvo"
      },
      "id": "FT1vlCAlLGvo",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset2=myDataset(train_df2,tokenizer, MAX_LEN)\n",
        "val_dataset2 = myDataset(val_df2,tokenizer,MAX_LEN)"
      ],
      "metadata": {
        "id": "hR9txfKTMOu7"
      },
      "id": "hR9txfKTMOu7",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader2 = torch.utils.data.DataLoader(\n",
        "    train_dataset2,\n",
        "    shuffle=True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers= 0 \n",
        "    )\n",
        "valLoader2 = torch.utils.data.DataLoader(\n",
        "    val_dataset2,\n",
        "    shuffle=False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers= 0 \n",
        "    )"
      ],
      "metadata": {
        "id": "dW2V-AzBrQGK"
      },
      "id": "dW2V-AzBrQGK",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,_,valid_loss_min= load_ckp(best_model_path,model,optimizer)\n",
        "print(valid_loss_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-grrAYMeBuol",
        "outputId": "dad0590e-6610-4896-9962-ca7b32787ed8"
      },
      "id": "-grrAYMeBuol",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10706023387019598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model=train_model(EPOCHS,trainLoader2,valLoader2,model, optimizer,ckpt_path,best_model_path,valid_loss_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gi_VALEucil",
        "outputId": "1a6c5ec3-b2db-4eb3-a7e8-e49a1ee7809f"
      },
      "id": "9Gi_VALEucil",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch[1]\n",
            "TRAIN BATCH 1/250====>train loss[0.24400586] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.22997821] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.20277646] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.20922163] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.19725994] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.18821281] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.17353845] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.16241735] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.16496048] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.16358655] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.16651003] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.17867123] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.18661779] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.18255882] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.18287333] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.18158351] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.17959618] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.18039071] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.17847909] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.18047679] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.18081882] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.18219961] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.18823612] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.18331250] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.18578867] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.18723869] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.18775314] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.19267411] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.19421442] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.19386601] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.19276946] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.19313996] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.19370056] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.19024259] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.19156532] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.19131826] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.18993188] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.18664507] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.18538832] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.18719595] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.18743399] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.18643418] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.19052522] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.19089424] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.18856627] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.18770134] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.18544830] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.18451675] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.18504116] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.18528429] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.18298679] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.18104587] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.18288073] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.18360389] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.18175786] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.18083337] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.17938558] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.17937628] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.17791606] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.17787955] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.17777841] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.17784617] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.17788754] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.17714695] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.17643164] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.17600194] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.17712457] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.17673467] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.17603600] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.17650046] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.17720515] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.17636650] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.17713709] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.17702158] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.17672656] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.17501394] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.17470971] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.17357846] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.17286278] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.17354113] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.17450495] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.17425309] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.17472659] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.17475557] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.17444854] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.17392676] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.17320119] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.17379780] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.17383528] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.17346424] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.17251663] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.17151509] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.17070756] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.17079092] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.17181456] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.17094057] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.17065886] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.17101153] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.17119897] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.17049828] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.17145301] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.17144041] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.17155220] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.17290694] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.17391071] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.17480457] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.17494961] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.17503158] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.17541984] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.17608297] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.17642644] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.17616159] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.17582497] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.17647530] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.17662408] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.17716195] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.17712738] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.17696017] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.17645241] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.17683677] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.17605951] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.17550590] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.17543159] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.17529412] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.17521207] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.17490386] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.17424639] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.17450422] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.17490717] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.17479764] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.17495952] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.17541897] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.17525075] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.17541717] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.17523812] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.17576189] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.17590187] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.17577677] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.17600340] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.17568904] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.17528886] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.17546096] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.17547875] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.17476677] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.17486104] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.17420444] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.17574685] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.17603390] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.17619931] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.17545742] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.17531183] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.17481788] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.17545171] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.17525841] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.17497714] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.17479952] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.17434950] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.17418481] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.17474386] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.17474823] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.17469496] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.17470776] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.17479351] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.17515461] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.17478609] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.17449657] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.17450331] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.17460608] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.17409642] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.17516779] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.17461274] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.17497148] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.17495523] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.17471479] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.17449378] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.17433818] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.17372374] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.17412630] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.17429213] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.17366254] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.17392114] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.17491399] | train accuracy[37.50000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.17482193] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.17513336] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.17530866] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.17487447] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.17454130] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.17433862] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.17489881] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.17516999] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.17520979] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.17488609] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.17489709] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.17452393] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.17400823] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.17395541] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.17478565] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.17563834] | train accuracy[43.75000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.17541716] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.17563846] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.17575018] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.17584344] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.17611204] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.17585102] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.17585966] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.17619397] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.17593093] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.17588794] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.17590872] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.17624295] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.17663893] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.17666200] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.17635716] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.17621693] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.17605326] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.17631078] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.17668373] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.17653765] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.17674221] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.17695539] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.17699822] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.17700827] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.17658579] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.17636874] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.17648483] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.17705197] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.17691062] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.17735180] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.17748671] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.17761902] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.17761175] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.17765344] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.17772816] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.17793946] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.17771010] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.17782956] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.17779077] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.17786078] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.17758136] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.17758202] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.17731783] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.17730090] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.17745386] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.17777596] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.17822217] | train accuracy[56.25000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.17826090] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.17797507] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.17764217] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.17763925] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.17731593] | train accuracy[50.00000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.11311245] | val accuracy[87.50000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.12114488] | val accuracy[75.00000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.13466865] | val accuracy[68.75000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.13793238] | val accuracy[87.50000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.14533049] | val accuracy[68.75000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.14343875] | val accuracy[81.25000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.13244286] | val accuracy[93.75000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.12974158] | val accuracy[93.75000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.12209431] | val accuracy[100.00000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.12574967] | val accuracy[87.50000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.12314870] | val accuracy[93.75000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.11976797] | val accuracy[93.75000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.12097066] | val accuracy[87.50000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.11761556] | val accuracy[93.75000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.11747227] | val accuracy[81.25000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.11763354] | val accuracy[87.50000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.11553672] | val accuracy[93.75000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.11614234] | val accuracy[81.25000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.11605032] | val accuracy[68.75000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.11480591] | val accuracy[87.50000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.11380648] | val accuracy[93.75000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.11359845] | val accuracy[87.50000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.11608397] | val accuracy[81.25000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.11424648] | val accuracy[87.50000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.11285371] | val accuracy[93.75000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.11148465] | val accuracy[93.75000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.11333931] | val accuracy[81.25000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.11182790] | val accuracy[93.75000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.11035719] | val accuracy[93.75000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.10869634] | val accuracy[100.00000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.11140631] | val accuracy[68.75000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.11110811] | val accuracy[87.50000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.11195284] | val accuracy[68.75000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.11063684] | val accuracy[100.00000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.11007267] | val accuracy[81.25000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.11057954] | val accuracy[75.00000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.10902279] | val accuracy[100.00000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.10799886] | val accuracy[93.75000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.10898137] | val accuracy[81.25000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.11076181] | val accuracy[75.00000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.11004081] | val accuracy[100.00000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.11024943] | val accuracy[75.00000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.11090696] | val accuracy[87.50000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.11171404] | val accuracy[68.75000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.11221571] | val accuracy[87.50000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.11301642] | val accuracy[75.00000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.11207389] | val accuracy[100.00000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.11243324] | val accuracy[81.25000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.11278753] | val accuracy[81.25000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.11337878] | val accuracy[75.00000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.11296797] | val accuracy[87.50000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.11227227] | val accuracy[93.75000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.11197553] | val accuracy[87.50000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.11247107] | val accuracy[75.00000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.11236292] | val accuracy[81.25000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.11220323] | val accuracy[87.50000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.11233295] | val accuracy[87.50000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.11332365] | val accuracy[75.00000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.11330795] | val accuracy[87.50000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.11329212] | val accuracy[81.25000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.11275297] | val accuracy[93.75000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.11305929] | val accuracy[87.50000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.11176633] | val accuracy[37.50000000%]\n",
            "epoch 1 end\n",
            "epoch[2]\n",
            "TRAIN BATCH 1/250====>train loss[0.08686573] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.09751308] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.13517570] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.11677573] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.11166540] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.10977810] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.10257290] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.10085262] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.10910156] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.10849284] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.10819309] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.10861059] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.10376211] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.10069937] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.09890268] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.09625488] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.09896550] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.09707057] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.09809308] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.10040451] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.09680717] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.09684612] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.09935897] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.10010319] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.09906769] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.09806141] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.09640450] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.09595108] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.09344141] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.09494101] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.09433404] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.09323017] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.09422691] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.09248415] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.09174431] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.09120820] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.09181015] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.08993519] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.08998460] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.08968761] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.08791065] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.08645239] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.08675749] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.08574329] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.08571121] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.08555610] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.08496502] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.08694312] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.08834402] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.08839499] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.08815018] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.08690159] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.08889130] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.08897395] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.08892179] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.08979228] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.09032369] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.09040201] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.08995254] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.08995399] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.09006556] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.08998122] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.09080168] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.08996928] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.09058790] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.09080708] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.09087186] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.09130533] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.09075433] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.09061229] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.09116758] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.09270063] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.09240257] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.09174681] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.09203100] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.09365693] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.09339808] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.09316561] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.09306403] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.09248266] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.09226348] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.09219003] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.09253232] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.09197774] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.09218033] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.09155958] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.09090481] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.09107736] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.09044793] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.09074997] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.09002343] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.09071808] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.09098683] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.09185707] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.09126729] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.09090914] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.09067634] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.09090112] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.09098616] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.09060795] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.09132035] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.09189635] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.09195201] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.09153495] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.09097562] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.09075702] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.09052546] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.09006085] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.09003800] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.09017524] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.09086603] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.09083604] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.09079283] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.09099696] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.09093066] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.09098820] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.09042225] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.09011504] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.08961347] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.09058811] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.09063625] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.09075265] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.09098582] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.09040406] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.09101850] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.09132570] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.09129049] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.09102744] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.09061273] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.09099198] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.09114465] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.09199073] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.09208358] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.09254953] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.09219896] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.09222732] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.09226420] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.09202484] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.09279899] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.09304339] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.09273516] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.09259598] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.09327818] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.09300441] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.09289549] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.09312498] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.09331394] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.09378096] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.09405523] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.09398415] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.09425260] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.09528197] | train accuracy[50.00000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.09574776] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.09623242] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.09637445] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.09616319] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.09586094] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.09666300] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.09693771] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.09667104] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.09655004] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.09644888] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.09658139] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.09655410] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.09656749] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.09648916] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.09625315] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.09582731] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.09596722] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.09598857] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.09598723] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.09581588] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.09598180] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.09576638] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.09621318] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.09609145] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.09619138] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.09608242] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.09645248] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.09613449] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.09635209] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.09681983] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.09707890] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.09714940] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.09701217] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.09696680] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.09726477] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.09742390] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.09721788] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.09718031] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.09695867] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.09673300] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.09711385] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.09705687] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.09703722] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.09693601] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.09666991] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.09670812] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.09706249] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.09715295] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.09745455] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.09743846] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.09742445] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.09724720] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.09714364] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.09720917] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.09781297] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.09820769] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.09815390] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.09860841] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.09854626] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.09860542] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.09864153] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.09861612] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.09886481] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.09875137] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.09866595] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.09871259] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.09876346] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.09838749] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.09848188] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.09859024] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.09903225] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.09913291] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.09947364] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.09941129] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.09919065] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.09913813] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.09969260] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.09950316] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.09931227] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.09945737] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.09966955] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.09959242] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.09961112] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.09957336] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.09961785] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.09936137] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.09944754] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.09964437] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.09978040] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.10000578] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.09991714] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.09975471] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.09986958] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.09993257] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.09967839] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.09996625] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.10028440] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.10032472] | train accuracy[43.75000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.04167980] | val accuracy[93.75000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.10384977] | val accuracy[75.00000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.09608023] | val accuracy[93.75000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.11011689] | val accuracy[81.25000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.13499950] | val accuracy[62.50000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.13644062] | val accuracy[75.00000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.12720003] | val accuracy[93.75000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.11696748] | val accuracy[93.75000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.10923415] | val accuracy[93.75000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.11693242] | val accuracy[68.75000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.11224551] | val accuracy[93.75000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.10586093] | val accuracy[100.00000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.10651338] | val accuracy[87.50000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.10665981] | val accuracy[87.50000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.10184553] | val accuracy[100.00000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.09915584] | val accuracy[93.75000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.09550101] | val accuracy[100.00000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.09544596] | val accuracy[81.25000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.09493627] | val accuracy[87.50000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.09401238] | val accuracy[87.50000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.09212523] | val accuracy[93.75000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.09080999] | val accuracy[87.50000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.09378889] | val accuracy[81.25000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.09376647] | val accuracy[87.50000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.09117198] | val accuracy[100.00000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.09008153] | val accuracy[93.75000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.09242064] | val accuracy[75.00000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.09078728] | val accuracy[93.75000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.08909630] | val accuracy[87.50000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.08710405] | val accuracy[100.00000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.09007392] | val accuracy[75.00000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.09259198] | val accuracy[81.25000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.09238676] | val accuracy[87.50000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.09098812] | val accuracy[93.75000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.09087828] | val accuracy[81.25000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.09221546] | val accuracy[75.00000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.09094058] | val accuracy[93.75000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.09009822] | val accuracy[100.00000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.09066870] | val accuracy[75.00000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.09271053] | val accuracy[68.75000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.09157429] | val accuracy[93.75000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.09102243] | val accuracy[93.75000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.09024293] | val accuracy[93.75000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.09118609] | val accuracy[75.00000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.09141436] | val accuracy[81.25000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.09163871] | val accuracy[81.25000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.09274445] | val accuracy[81.25000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.09239584] | val accuracy[87.50000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.09264117] | val accuracy[81.25000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.09592230] | val accuracy[75.00000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.09492355] | val accuracy[93.75000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.09374182] | val accuracy[93.75000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.09469758] | val accuracy[81.25000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.09467851] | val accuracy[87.50000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.09426357] | val accuracy[93.75000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.09438198] | val accuracy[87.50000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.09519322] | val accuracy[81.25000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.09549008] | val accuracy[87.50000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.09512509] | val accuracy[87.50000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.09515843] | val accuracy[87.50000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.09435258] | val accuracy[100.00000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.09483427] | val accuracy[87.50000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.09375710] | val accuracy[37.50000000%]\n",
            "previous Val_loss_min=0.10706023; new val_loss_min=0.09375710\n",
            "SAVED\n",
            "epoch 2 end\n",
            "epoch[3]\n",
            "TRAIN BATCH 1/250====>train loss[0.07043628] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.07354438] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.07308679] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.08129174] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.08272581] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.08411778] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.07605991] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.07470976] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.07283793] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.07427798] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.06937587] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.07176475] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.07515411] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.07749794] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.07427049] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.07119360] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.06793710] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.06695496] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.06568963] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.06611779] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.07106319] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.07005450] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.06824610] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.06710059] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.06562858] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.06720979] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.06734210] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.06877769] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.06908030] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.06723623] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.06911818] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.07129082] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.07263197] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.07354285] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.07510142] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.07543764] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.07509131] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.07371219] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.07371403] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.07306806] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.07303995] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.07296373] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.07396918] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.07485666] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.07374015] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.07366143] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.07285559] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.07214020] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.07193067] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.07172566] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.07058976] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.07039362] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.07215528] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.07119670] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.07056987] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.06965790] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.07107342] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.07156498] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.07057463] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.07154950] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.07103800] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.07115685] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.07050179] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.06972822] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.06998893] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.07004449] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.07009583] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.07069892] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.06992889] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.06917624] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.06858927] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.06826338] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.06766951] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.06717010] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.06696788] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.06630371] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.06571893] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.06528417] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.06537127] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.06529172] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.06548087] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.06497077] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.06449079] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.06438017] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.06449401] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.06472529] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.06426498] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.06478452] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.06429104] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.06444203] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.06429076] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.06456073] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.06491912] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.06528781] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.06530757] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.06559049] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.06562534] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.06513748] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.06487938] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.06467973] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.06492869] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.06439055] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.06389459] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.06412399] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.06380024] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.06464169] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.06436929] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.06442120] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.06477822] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.06513304] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.06569527] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.06537503] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.06575865] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.06594015] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.06559184] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.06529165] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.06517749] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.06505846] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.06475131] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.06432702] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.06417828] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.06423991] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.06391714] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.06442442] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.06448577] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.06451397] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.06471020] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.06457299] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.06455623] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.06482663] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.06490854] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.06465842] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.06441554] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.06410572] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.06385490] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.06427656] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.06404434] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.06415078] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.06382475] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.06361234] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.06395415] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.06358128] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.06366535] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.06350201] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.06402262] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.06486369] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.06541870] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.06577105] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.06597490] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.06607819] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.06578954] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.06573254] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.06549211] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.06575919] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.06623784] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.06641279] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.06632780] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.06621816] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.06656115] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.06668469] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.06660042] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.06629467] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.06664412] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.06706226] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.06706460] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.06715799] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.06750254] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.06718069] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.06687382] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.06700020] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.06701000] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.06739699] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.06745395] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.06741720] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.06742667] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.06734827] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.06781013] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.06828472] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.06855494] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.06879610] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.06887056] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.06868025] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.06854627] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.06827383] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.06827404] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.06834238] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.06878228] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.06865396] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.06879284] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.06877804] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.06893920] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.06917078] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.06938841] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.06914617] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.06900437] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.06930607] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.06928881] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.06962413] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.06955131] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.06975573] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.06952656] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.06990483] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.06973293] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.06970868] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.06981020] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.07019209] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.07002710] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.06995258] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.06984504] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.06991957] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.06970183] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.06974450] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.06971771] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.06948150] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.06958489] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.06936693] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.06936213] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.06927827] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.06923214] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.06926940] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.06977439] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.06986422] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.06987994] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.06986226] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.06990058] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.06983301] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.07042437] | train accuracy[62.50000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.07043273] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.07037070] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.07066567] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.07074689] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.07111668] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.07128240] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.07133154] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.07121579] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.07102118] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.07098873] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.07084687] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.07092708] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.07084357] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.07111448] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.07128049] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.07155434] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.07141588] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.07134710] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.07114019] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.07113321] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.07100427] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.07097739] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.07096121] | train accuracy[50.00000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.02877836] | val accuracy[100.00000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.09218494] | val accuracy[68.75000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.10431734] | val accuracy[87.50000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.09767563] | val accuracy[93.75000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.10250211] | val accuracy[81.25000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.10967864] | val accuracy[81.25000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.09964197] | val accuracy[93.75000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.09857640] | val accuracy[87.50000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.09271368] | val accuracy[93.75000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.09665644] | val accuracy[87.50000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.09182837] | val accuracy[93.75000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.09035505] | val accuracy[93.75000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.09521862] | val accuracy[81.25000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.09290452] | val accuracy[93.75000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.08862262] | val accuracy[93.75000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.08812682] | val accuracy[87.50000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.08417328] | val accuracy[100.00000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.08630767] | val accuracy[81.25000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.08562415] | val accuracy[87.50000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.08241778] | val accuracy[100.00000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.07952439] | val accuracy[100.00000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.07702759] | val accuracy[100.00000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.08104979] | val accuracy[75.00000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.07941135] | val accuracy[93.75000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.07735695] | val accuracy[100.00000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.07493339] | val accuracy[100.00000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.07469154] | val accuracy[87.50000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.07284951] | val accuracy[100.00000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.07160489] | val accuracy[93.75000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.07002696] | val accuracy[100.00000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.07173591] | val accuracy[81.25000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.07057888] | val accuracy[93.75000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.07084169] | val accuracy[93.75000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.06931060] | val accuracy[100.00000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.07160858] | val accuracy[81.25000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.07309701] | val accuracy[81.25000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.07144088] | val accuracy[100.00000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.07030214] | val accuracy[100.00000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.07106878] | val accuracy[87.50000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.07291844] | val accuracy[81.25000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.07252819] | val accuracy[87.50000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.07127167] | val accuracy[100.00000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.07166627] | val accuracy[93.75000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.07097209] | val accuracy[87.50000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.07380503] | val accuracy[75.00000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.07359206] | val accuracy[93.75000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.07381376] | val accuracy[93.75000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.07330353] | val accuracy[93.75000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.07336733] | val accuracy[93.75000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.07372894] | val accuracy[87.50000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.07308433] | val accuracy[93.75000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.07206871] | val accuracy[100.00000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.07179208] | val accuracy[87.50000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.07103068] | val accuracy[100.00000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.07041789] | val accuracy[100.00000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.06973662] | val accuracy[100.00000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.06951407] | val accuracy[93.75000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.07048422] | val accuracy[81.25000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.07068256] | val accuracy[93.75000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.07122820] | val accuracy[87.50000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.07066124] | val accuracy[93.75000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.07063136] | val accuracy[93.75000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.06972345] | val accuracy[37.50000000%]\n",
            "previous Val_loss_min=0.09375710; new val_loss_min=0.06972345\n",
            "SAVED\n",
            "epoch 3 end\n",
            "epoch[4]\n",
            "TRAIN BATCH 1/250====>train loss[0.03702256] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 2/250====>train loss[0.04025506] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 3/250====>train loss[0.03998033] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 4/250====>train loss[0.03909141] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 5/250====>train loss[0.03734067] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 6/250====>train loss[0.03775408] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 7/250====>train loss[0.03858983] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 8/250====>train loss[0.03888170] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 9/250====>train loss[0.03884654] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 10/250====>train loss[0.03936965] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 11/250====>train loss[0.03718098] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 12/250====>train loss[0.03824228] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 13/250====>train loss[0.03611375] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 14/250====>train loss[0.03563780] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 15/250====>train loss[0.03452497] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 16/250====>train loss[0.03440740] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 17/250====>train loss[0.03517642] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 18/250====>train loss[0.03778593] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 19/250====>train loss[0.03656892] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 20/250====>train loss[0.03692436] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 21/250====>train loss[0.03791436] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 22/250====>train loss[0.04175260] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 23/250====>train loss[0.04320071] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 24/250====>train loss[0.04474767] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 25/250====>train loss[0.04964141] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 26/250====>train loss[0.04832735] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 27/250====>train loss[0.04832022] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 28/250====>train loss[0.04783302] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 29/250====>train loss[0.04823255] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 30/250====>train loss[0.04867083] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 31/250====>train loss[0.04751002] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 32/250====>train loss[0.04748302] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 33/250====>train loss[0.04835492] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 34/250====>train loss[0.04787755] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 35/250====>train loss[0.04767596] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 36/250====>train loss[0.04756063] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 37/250====>train loss[0.04819565] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 38/250====>train loss[0.04825535] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 39/250====>train loss[0.05123194] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 40/250====>train loss[0.05091650] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 41/250====>train loss[0.05175076] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 42/250====>train loss[0.05079922] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 43/250====>train loss[0.05099908] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 44/250====>train loss[0.05276287] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 45/250====>train loss[0.05309037] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 46/250====>train loss[0.05339521] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 47/250====>train loss[0.05391602] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 48/250====>train loss[0.05384193] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 49/250====>train loss[0.05491870] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 50/250====>train loss[0.05420987] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 51/250====>train loss[0.05418032] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 52/250====>train loss[0.05459567] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 53/250====>train loss[0.05403789] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 54/250====>train loss[0.05343428] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 55/250====>train loss[0.05388564] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 56/250====>train loss[0.05433269] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 57/250====>train loss[0.05525266] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 58/250====>train loss[0.05568167] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 59/250====>train loss[0.05632080] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 60/250====>train loss[0.05624727] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 61/250====>train loss[0.05567913] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 62/250====>train loss[0.05544150] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 63/250====>train loss[0.05479427] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 64/250====>train loss[0.05454737] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 65/250====>train loss[0.05472251] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 66/250====>train loss[0.05405979] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 67/250====>train loss[0.05399752] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 68/250====>train loss[0.05418573] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 69/250====>train loss[0.05406287] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 70/250====>train loss[0.05370252] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 71/250====>train loss[0.05375854] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 72/250====>train loss[0.05428014] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 73/250====>train loss[0.05368016] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 74/250====>train loss[0.05435327] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 75/250====>train loss[0.05386439] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 76/250====>train loss[0.05363770] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 77/250====>train loss[0.05322727] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 78/250====>train loss[0.05347910] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 79/250====>train loss[0.05303631] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 80/250====>train loss[0.05261060] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 81/250====>train loss[0.05272519] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 82/250====>train loss[0.05364837] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 83/250====>train loss[0.05472635] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 84/250====>train loss[0.05501819] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 85/250====>train loss[0.05506286] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 86/250====>train loss[0.05554160] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 87/250====>train loss[0.05544334] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 88/250====>train loss[0.05567762] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 89/250====>train loss[0.05597477] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 90/250====>train loss[0.05579083] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 91/250====>train loss[0.05571701] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 92/250====>train loss[0.05520839] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 93/250====>train loss[0.05572807] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 94/250====>train loss[0.05528004] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 95/250====>train loss[0.05509425] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 96/250====>train loss[0.05489370] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 97/250====>train loss[0.05454690] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 98/250====>train loss[0.05428337] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 99/250====>train loss[0.05425930] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 100/250====>train loss[0.05473212] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 101/250====>train loss[0.05428888] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 102/250====>train loss[0.05427872] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 103/250====>train loss[0.05450103] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 104/250====>train loss[0.05424623] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 105/250====>train loss[0.05481774] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 106/250====>train loss[0.05476322] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 107/250====>train loss[0.05442106] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 108/250====>train loss[0.05412259] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 109/250====>train loss[0.05378584] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 110/250====>train loss[0.05365730] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 111/250====>train loss[0.05380010] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 112/250====>train loss[0.05375109] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 113/250====>train loss[0.05400780] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 114/250====>train loss[0.05401774] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 115/250====>train loss[0.05364956] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 116/250====>train loss[0.05426960] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 117/250====>train loss[0.05440473] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 118/250====>train loss[0.05451095] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 119/250====>train loss[0.05442745] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 120/250====>train loss[0.05418965] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 121/250====>train loss[0.05401355] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 122/250====>train loss[0.05455139] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 123/250====>train loss[0.05422199] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 124/250====>train loss[0.05388350] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 125/250====>train loss[0.05362525] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 126/250====>train loss[0.05380196] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 127/250====>train loss[0.05400942] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 128/250====>train loss[0.05427139] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 129/250====>train loss[0.05408110] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 130/250====>train loss[0.05427101] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 131/250====>train loss[0.05396298] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 132/250====>train loss[0.05412126] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 133/250====>train loss[0.05410842] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 134/250====>train loss[0.05402503] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 135/250====>train loss[0.05373058] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 136/250====>train loss[0.05418054] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 137/250====>train loss[0.05412213] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 138/250====>train loss[0.05379096] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 139/250====>train loss[0.05349940] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 140/250====>train loss[0.05341317] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 141/250====>train loss[0.05329296] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 142/250====>train loss[0.05304851] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 143/250====>train loss[0.05360972] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 144/250====>train loss[0.05400824] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 145/250====>train loss[0.05381747] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 146/250====>train loss[0.05399771] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 147/250====>train loss[0.05391000] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 148/250====>train loss[0.05396502] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 149/250====>train loss[0.05375154] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 150/250====>train loss[0.05425141] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 151/250====>train loss[0.05398105] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 152/250====>train loss[0.05369508] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 153/250====>train loss[0.05344539] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 154/250====>train loss[0.05317538] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 155/250====>train loss[0.05295313] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 156/250====>train loss[0.05304747] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 157/250====>train loss[0.05287107] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 158/250====>train loss[0.05309382] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 159/250====>train loss[0.05294563] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 160/250====>train loss[0.05280161] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 161/250====>train loss[0.05293805] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 162/250====>train loss[0.05279869] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 163/250====>train loss[0.05268694] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 164/250====>train loss[0.05302115] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 165/250====>train loss[0.05316040] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 166/250====>train loss[0.05315684] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 167/250====>train loss[0.05294285] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 168/250====>train loss[0.05311609] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 169/250====>train loss[0.05293344] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 170/250====>train loss[0.05280026] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 171/250====>train loss[0.05310223] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 172/250====>train loss[0.05317591] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 173/250====>train loss[0.05298165] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 174/250====>train loss[0.05308010] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 175/250====>train loss[0.05297340] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 176/250====>train loss[0.05286652] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 177/250====>train loss[0.05276551] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 178/250====>train loss[0.05265100] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 179/250====>train loss[0.05293822] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 180/250====>train loss[0.05269732] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 181/250====>train loss[0.05266024] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 182/250====>train loss[0.05291142] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 183/250====>train loss[0.05311164] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 184/250====>train loss[0.05375569] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 185/250====>train loss[0.05399230] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 186/250====>train loss[0.05399576] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 187/250====>train loss[0.05417305] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 188/250====>train loss[0.05404165] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 189/250====>train loss[0.05391778] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 190/250====>train loss[0.05406783] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 191/250====>train loss[0.05458128] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 192/250====>train loss[0.05437758] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 193/250====>train loss[0.05451787] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 194/250====>train loss[0.05463657] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 195/250====>train loss[0.05501447] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 196/250====>train loss[0.05480490] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 197/250====>train loss[0.05473855] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 198/250====>train loss[0.05506117] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 199/250====>train loss[0.05535768] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 200/250====>train loss[0.05538613] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 201/250====>train loss[0.05562485] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 202/250====>train loss[0.05551425] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 203/250====>train loss[0.05570066] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 204/250====>train loss[0.05593739] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 205/250====>train loss[0.05600568] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 206/250====>train loss[0.05593920] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 207/250====>train loss[0.05615774] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 208/250====>train loss[0.05597272] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 209/250====>train loss[0.05606844] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 210/250====>train loss[0.05609344] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 211/250====>train loss[0.05648315] | train accuracy[68.75000000%]\n",
            "TRAIN BATCH 212/250====>train loss[0.05654234] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 213/250====>train loss[0.05642855] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 214/250====>train loss[0.05623012] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 215/250====>train loss[0.05613485] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 216/250====>train loss[0.05613944] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 217/250====>train loss[0.05601253] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 218/250====>train loss[0.05614138] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 219/250====>train loss[0.05646415] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 220/250====>train loss[0.05629912] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 221/250====>train loss[0.05664150] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 222/250====>train loss[0.05657799] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 223/250====>train loss[0.05641422] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 224/250====>train loss[0.05657054] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 225/250====>train loss[0.05656879] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 226/250====>train loss[0.05683246] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 227/250====>train loss[0.05707720] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 228/250====>train loss[0.05706108] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 229/250====>train loss[0.05697405] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 230/250====>train loss[0.05702131] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 231/250====>train loss[0.05684404] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 232/250====>train loss[0.05681164] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 233/250====>train loss[0.05669035] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 234/250====>train loss[0.05705366] | train accuracy[75.00000000%]\n",
            "TRAIN BATCH 235/250====>train loss[0.05710758] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 236/250====>train loss[0.05709595] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 237/250====>train loss[0.05727436] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 238/250====>train loss[0.05708184] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 239/250====>train loss[0.05714227] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 240/250====>train loss[0.05707312] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 241/250====>train loss[0.05691491] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 242/250====>train loss[0.05691917] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 243/250====>train loss[0.05684284] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 244/250====>train loss[0.05683087] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 245/250====>train loss[0.05664528] | train accuracy[100.00000000%]\n",
            "TRAIN BATCH 246/250====>train loss[0.05683700] | train accuracy[81.25000000%]\n",
            "TRAIN BATCH 247/250====>train loss[0.05687496] | train accuracy[87.50000000%]\n",
            "TRAIN BATCH 248/250====>train loss[0.05687847] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 249/250====>train loss[0.05683374] | train accuracy[93.75000000%]\n",
            "TRAIN BATCH 250/250====>train loss[0.05666361] | train accuracy[56.25000000%]\n",
            "validation batch index:0/63\n",
            "VALIDATION BATCH 1/63====>val loss[0.04263669] | val accuracy[87.50000000%]\n",
            "validation batch index:1/63\n",
            "VALIDATION BATCH 2/63====>val loss[0.05659823] | val accuracy[87.50000000%]\n",
            "validation batch index:2/63\n",
            "VALIDATION BATCH 3/63====>val loss[0.07906691] | val accuracy[87.50000000%]\n",
            "validation batch index:3/63\n",
            "VALIDATION BATCH 4/63====>val loss[0.07967643] | val accuracy[93.75000000%]\n",
            "validation batch index:4/63\n",
            "VALIDATION BATCH 5/63====>val loss[0.08364666] | val accuracy[87.50000000%]\n",
            "validation batch index:5/63\n",
            "VALIDATION BATCH 6/63====>val loss[0.10044968] | val accuracy[75.00000000%]\n",
            "validation batch index:6/63\n",
            "VALIDATION BATCH 7/63====>val loss[0.08744555] | val accuracy[100.00000000%]\n",
            "validation batch index:7/63\n",
            "VALIDATION BATCH 8/63====>val loss[0.08092695] | val accuracy[93.75000000%]\n",
            "validation batch index:8/63\n",
            "VALIDATION BATCH 9/63====>val loss[0.07447128] | val accuracy[93.75000000%]\n",
            "validation batch index:9/63\n",
            "VALIDATION BATCH 10/63====>val loss[0.07672147] | val accuracy[87.50000000%]\n",
            "validation batch index:10/63\n",
            "VALIDATION BATCH 11/63====>val loss[0.07332000] | val accuracy[93.75000000%]\n",
            "validation batch index:11/63\n",
            "VALIDATION BATCH 12/63====>val loss[0.06914150] | val accuracy[100.00000000%]\n",
            "validation batch index:12/63\n",
            "VALIDATION BATCH 13/63====>val loss[0.07424113] | val accuracy[81.25000000%]\n",
            "validation batch index:13/63\n",
            "VALIDATION BATCH 14/63====>val loss[0.07074206] | val accuracy[93.75000000%]\n",
            "validation batch index:14/63\n",
            "VALIDATION BATCH 15/63====>val loss[0.06829554] | val accuracy[100.00000000%]\n",
            "validation batch index:15/63\n",
            "VALIDATION BATCH 16/63====>val loss[0.06973986] | val accuracy[93.75000000%]\n",
            "validation batch index:16/63\n",
            "VALIDATION BATCH 17/63====>val loss[0.06599330] | val accuracy[100.00000000%]\n",
            "validation batch index:17/63\n",
            "VALIDATION BATCH 18/63====>val loss[0.06843816] | val accuracy[87.50000000%]\n",
            "validation batch index:18/63\n",
            "VALIDATION BATCH 19/63====>val loss[0.07050302] | val accuracy[87.50000000%]\n",
            "validation batch index:19/63\n",
            "VALIDATION BATCH 20/63====>val loss[0.06760776] | val accuracy[100.00000000%]\n",
            "validation batch index:20/63\n",
            "VALIDATION BATCH 21/63====>val loss[0.06473977] | val accuracy[100.00000000%]\n",
            "validation batch index:21/63\n",
            "VALIDATION BATCH 22/63====>val loss[0.06249396] | val accuracy[100.00000000%]\n",
            "validation batch index:22/63\n",
            "VALIDATION BATCH 23/63====>val loss[0.06802787] | val accuracy[81.25000000%]\n",
            "validation batch index:23/63\n",
            "VALIDATION BATCH 24/63====>val loss[0.06824098] | val accuracy[93.75000000%]\n",
            "validation batch index:24/63\n",
            "VALIDATION BATCH 25/63====>val loss[0.06583426] | val accuracy[100.00000000%]\n",
            "validation batch index:25/63\n",
            "VALIDATION BATCH 26/63====>val loss[0.06389351] | val accuracy[100.00000000%]\n",
            "validation batch index:26/63\n",
            "VALIDATION BATCH 27/63====>val loss[0.06234911] | val accuracy[93.75000000%]\n",
            "validation batch index:27/63\n",
            "VALIDATION BATCH 28/63====>val loss[0.06291915] | val accuracy[87.50000000%]\n",
            "validation batch index:28/63\n",
            "VALIDATION BATCH 29/63====>val loss[0.06177021] | val accuracy[93.75000000%]\n",
            "validation batch index:29/63\n",
            "VALIDATION BATCH 30/63====>val loss[0.06020892] | val accuracy[100.00000000%]\n",
            "validation batch index:30/63\n",
            "VALIDATION BATCH 31/63====>val loss[0.06215042] | val accuracy[81.25000000%]\n",
            "validation batch index:31/63\n",
            "VALIDATION BATCH 32/63====>val loss[0.06058692] | val accuracy[100.00000000%]\n",
            "validation batch index:32/63\n",
            "VALIDATION BATCH 33/63====>val loss[0.05957869] | val accuracy[100.00000000%]\n",
            "validation batch index:33/63\n",
            "VALIDATION BATCH 34/63====>val loss[0.05975178] | val accuracy[93.75000000%]\n",
            "validation batch index:34/63\n",
            "VALIDATION BATCH 35/63====>val loss[0.06040920] | val accuracy[93.75000000%]\n",
            "validation batch index:35/63\n",
            "VALIDATION BATCH 36/63====>val loss[0.06250062] | val accuracy[81.25000000%]\n",
            "validation batch index:36/63\n",
            "VALIDATION BATCH 37/63====>val loss[0.06100551] | val accuracy[100.00000000%]\n",
            "validation batch index:37/63\n",
            "VALIDATION BATCH 38/63====>val loss[0.06103053] | val accuracy[93.75000000%]\n",
            "validation batch index:38/63\n",
            "VALIDATION BATCH 39/63====>val loss[0.06101580] | val accuracy[93.75000000%]\n",
            "validation batch index:39/63\n",
            "VALIDATION BATCH 40/63====>val loss[0.06238846] | val accuracy[87.50000000%]\n",
            "validation batch index:40/63\n",
            "VALIDATION BATCH 41/63====>val loss[0.06122604] | val accuracy[100.00000000%]\n",
            "validation batch index:41/63\n",
            "VALIDATION BATCH 42/63====>val loss[0.06024025] | val accuracy[93.75000000%]\n",
            "validation batch index:42/63\n",
            "VALIDATION BATCH 43/63====>val loss[0.06049156] | val accuracy[93.75000000%]\n",
            "validation batch index:43/63\n",
            "VALIDATION BATCH 44/63====>val loss[0.05964678] | val accuracy[100.00000000%]\n",
            "validation batch index:44/63\n",
            "VALIDATION BATCH 45/63====>val loss[0.06120573] | val accuracy[87.50000000%]\n",
            "validation batch index:45/63\n",
            "VALIDATION BATCH 46/63====>val loss[0.06075833] | val accuracy[93.75000000%]\n",
            "validation batch index:46/63\n",
            "VALIDATION BATCH 47/63====>val loss[0.05964924] | val accuracy[100.00000000%]\n",
            "validation batch index:47/63\n",
            "VALIDATION BATCH 48/63====>val loss[0.05883375] | val accuracy[100.00000000%]\n",
            "validation batch index:48/63\n",
            "VALIDATION BATCH 49/63====>val loss[0.05914869] | val accuracy[93.75000000%]\n",
            "validation batch index:49/63\n",
            "VALIDATION BATCH 50/63====>val loss[0.06129148] | val accuracy[87.50000000%]\n",
            "validation batch index:50/63\n",
            "VALIDATION BATCH 51/63====>val loss[0.06060168] | val accuracy[93.75000000%]\n",
            "validation batch index:51/63\n",
            "VALIDATION BATCH 52/63====>val loss[0.05985543] | val accuracy[100.00000000%]\n",
            "validation batch index:52/63\n",
            "VALIDATION BATCH 53/63====>val loss[0.06031931] | val accuracy[87.50000000%]\n",
            "validation batch index:53/63\n",
            "VALIDATION BATCH 54/63====>val loss[0.05997027] | val accuracy[93.75000000%]\n",
            "validation batch index:54/63\n",
            "VALIDATION BATCH 55/63====>val loss[0.05931072] | val accuracy[100.00000000%]\n",
            "validation batch index:55/63\n",
            "VALIDATION BATCH 56/63====>val loss[0.05859836] | val accuracy[93.75000000%]\n",
            "validation batch index:56/63\n",
            "VALIDATION BATCH 57/63====>val loss[0.05960551] | val accuracy[81.25000000%]\n",
            "validation batch index:57/63\n",
            "VALIDATION BATCH 58/63====>val loss[0.05996948] | val accuracy[93.75000000%]\n",
            "validation batch index:58/63\n",
            "VALIDATION BATCH 59/63====>val loss[0.06008050] | val accuracy[93.75000000%]\n",
            "validation batch index:59/63\n",
            "VALIDATION BATCH 60/63====>val loss[0.05943678] | val accuracy[100.00000000%]\n",
            "validation batch index:60/63\n",
            "VALIDATION BATCH 61/63====>val loss[0.05896274] | val accuracy[93.75000000%]\n",
            "validation batch index:61/63\n",
            "VALIDATION BATCH 62/63====>val loss[0.05929896] | val accuracy[93.75000000%]\n",
            "validation batch index:62/63\n",
            "VALIDATION BATCH 63/63====>val loss[0.05846651] | val accuracy[37.50000000%]\n",
            "previous Val_loss_min=0.06972345; new val_loss_min=0.05846651\n",
            "SAVED\n",
            "epoch 4 end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test model**"
      ],
      "metadata": {
        "id": "_N_bvNsA-2JV"
      },
      "id": "_N_bvNsA-2JV"
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = myDataset(df_test,tokenizer,MAX_LEN)\n",
        "testLoader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers= 0 \n",
        "    )\n"
      ],
      "metadata": {
        "id": "XegQX51Oum4U"
      },
      "id": "XegQX51Oum4U",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "test_accList =[]\n",
        "test_loss=0\n",
        "model.eval() \n",
        "with torch.no_grad():\n",
        "  for index, batch in enumerate(testLoader):\n",
        "    input_ids= batch['input_ids'].to(device, dtype= torch.long)\n",
        "    attention_mask = batch['attention_mask'].to(device, dtype= torch.long)\n",
        "    token_type_ids= batch['token_type_ids'].to(device, dtype= torch.long)\n",
        "    targets = batch['targets'].to(device, dtype= torch.float)\n",
        "    \n",
        "    output =model(input_ids,attention_mask,token_type_ids)\n",
        "    \n",
        "    loss= loss_fn(output,targets)\n",
        "    test_acc= accuracy(output,targets)\n",
        "    test_accList+= [test_acc]\n",
        "    test_loss = test_loss + ((1 / (index + 1)) * (loss.item() - test_loss))\n",
        "    print(\"TEST BATCH {}/{}====>test loss[{:.8f}] | test accuracy[{:.8f}%]\".format(index+1,len(testLoader) , test_loss, test_acc ))\n",
        "    #final_output = torch.sigmoid(output).cpu().detach().numpy()\n",
        "    #print(np.argmax(targets.cpu().numpy(),axis=1), np.argmax(final_output, axis=1) )\n",
        "print(\"AVG Accuracy = \", sum(test_accList)/len(test_accList))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w30iCyY9wM_W",
        "outputId": "9989baeb-ff89-4728-ba74-ab45135a3c1f"
      },
      "id": "w30iCyY9wM_W",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST BATCH 1/758====>test loss[0.17626327] | test accuracy[81.25000000%]\n",
            "TEST BATCH 2/758====>test loss[0.20837490] | test accuracy[75.00000000%]\n",
            "TEST BATCH 3/758====>test loss[0.18197175] | test accuracy[81.25000000%]\n",
            "TEST BATCH 4/758====>test loss[0.18138437] | test accuracy[81.25000000%]\n",
            "TEST BATCH 5/758====>test loss[0.15669663] | test accuracy[93.75000000%]\n",
            "TEST BATCH 6/758====>test loss[0.16370901] | test accuracy[81.25000000%]\n",
            "TEST BATCH 7/758====>test loss[0.17030768] | test accuracy[68.75000000%]\n",
            "TEST BATCH 8/758====>test loss[0.15309876] | test accuracy[93.75000000%]\n",
            "TEST BATCH 9/758====>test loss[0.13683048] | test accuracy[100.00000000%]\n",
            "TEST BATCH 10/758====>test loss[0.12447920] | test accuracy[100.00000000%]\n",
            "TEST BATCH 11/758====>test loss[0.12011157] | test accuracy[93.75000000%]\n",
            "TEST BATCH 12/758====>test loss[0.12753581] | test accuracy[75.00000000%]\n",
            "TEST BATCH 13/758====>test loss[0.12085439] | test accuracy[93.75000000%]\n",
            "TEST BATCH 14/758====>test loss[0.11545673] | test accuracy[93.75000000%]\n",
            "TEST BATCH 15/758====>test loss[0.11281491] | test accuracy[87.50000000%]\n",
            "TEST BATCH 16/758====>test loss[0.10907371] | test accuracy[93.75000000%]\n",
            "TEST BATCH 17/758====>test loss[0.10845718] | test accuracy[87.50000000%]\n",
            "TEST BATCH 18/758====>test loss[0.10726664] | test accuracy[87.50000000%]\n",
            "TEST BATCH 19/758====>test loss[0.11488581] | test accuracy[75.00000000%]\n",
            "TEST BATCH 20/758====>test loss[0.11487033] | test accuracy[75.00000000%]\n",
            "TEST BATCH 21/758====>test loss[0.11180358] | test accuracy[93.75000000%]\n",
            "TEST BATCH 22/758====>test loss[0.10992527] | test accuracy[87.50000000%]\n",
            "TEST BATCH 23/758====>test loss[0.11275604] | test accuracy[81.25000000%]\n",
            "TEST BATCH 24/758====>test loss[0.11128662] | test accuracy[93.75000000%]\n",
            "TEST BATCH 25/758====>test loss[0.11157269] | test accuracy[81.25000000%]\n",
            "TEST BATCH 26/758====>test loss[0.11945048] | test accuracy[75.00000000%]\n",
            "TEST BATCH 27/758====>test loss[0.11962946] | test accuracy[87.50000000%]\n",
            "TEST BATCH 28/758====>test loss[0.11989230] | test accuracy[81.25000000%]\n",
            "TEST BATCH 29/758====>test loss[0.12745284] | test accuracy[62.50000000%]\n",
            "TEST BATCH 30/758====>test loss[0.12614703] | test accuracy[87.50000000%]\n",
            "TEST BATCH 31/758====>test loss[0.12627362] | test accuracy[75.00000000%]\n",
            "TEST BATCH 32/758====>test loss[0.12435169] | test accuracy[87.50000000%]\n",
            "TEST BATCH 33/758====>test loss[0.12085275] | test accuracy[100.00000000%]\n",
            "TEST BATCH 34/758====>test loss[0.12133222] | test accuracy[75.00000000%]\n",
            "TEST BATCH 35/758====>test loss[0.11805179] | test accuracy[100.00000000%]\n",
            "TEST BATCH 36/758====>test loss[0.11919234] | test accuracy[87.50000000%]\n",
            "TEST BATCH 37/758====>test loss[0.11874212] | test accuracy[87.50000000%]\n",
            "TEST BATCH 38/758====>test loss[0.12568238] | test accuracy[56.25000000%]\n",
            "TEST BATCH 39/758====>test loss[0.13018022] | test accuracy[62.50000000%]\n",
            "TEST BATCH 40/758====>test loss[0.12841301] | test accuracy[93.75000000%]\n",
            "TEST BATCH 41/758====>test loss[0.12682756] | test accuracy[87.50000000%]\n",
            "TEST BATCH 42/758====>test loss[0.12633520] | test accuracy[81.25000000%]\n",
            "TEST BATCH 43/758====>test loss[0.12637910] | test accuracy[81.25000000%]\n",
            "TEST BATCH 44/758====>test loss[0.12932360] | test accuracy[62.50000000%]\n",
            "TEST BATCH 45/758====>test loss[0.12835544] | test accuracy[87.50000000%]\n",
            "TEST BATCH 46/758====>test loss[0.12887179] | test accuracy[87.50000000%]\n",
            "TEST BATCH 47/758====>test loss[0.12700751] | test accuracy[93.75000000%]\n",
            "TEST BATCH 48/758====>test loss[0.12686469] | test accuracy[87.50000000%]\n",
            "TEST BATCH 49/758====>test loss[0.12554161] | test accuracy[93.75000000%]\n",
            "TEST BATCH 50/758====>test loss[0.12509373] | test accuracy[87.50000000%]\n",
            "TEST BATCH 51/758====>test loss[0.12481435] | test accuracy[87.50000000%]\n",
            "TEST BATCH 52/758====>test loss[0.12520476] | test accuracy[81.25000000%]\n",
            "TEST BATCH 53/758====>test loss[0.12494008] | test accuracy[81.25000000%]\n",
            "TEST BATCH 54/758====>test loss[0.12368092] | test accuracy[93.75000000%]\n",
            "TEST BATCH 55/758====>test loss[0.12285829] | test accuracy[81.25000000%]\n",
            "TEST BATCH 56/758====>test loss[0.12256983] | test accuracy[87.50000000%]\n",
            "TEST BATCH 57/758====>test loss[0.12132050] | test accuracy[93.75000000%]\n",
            "TEST BATCH 58/758====>test loss[0.12020271] | test accuracy[93.75000000%]\n",
            "TEST BATCH 59/758====>test loss[0.12168332] | test accuracy[75.00000000%]\n",
            "TEST BATCH 60/758====>test loss[0.12163868] | test accuracy[81.25000000%]\n",
            "TEST BATCH 61/758====>test loss[0.12478944] | test accuracy[62.50000000%]\n",
            "TEST BATCH 62/758====>test loss[0.12411330] | test accuracy[87.50000000%]\n",
            "TEST BATCH 63/758====>test loss[0.12716348] | test accuracy[75.00000000%]\n",
            "TEST BATCH 64/758====>test loss[0.12633451] | test accuracy[93.75000000%]\n",
            "TEST BATCH 65/758====>test loss[0.12590747] | test accuracy[81.25000000%]\n",
            "TEST BATCH 66/758====>test loss[0.12503996] | test accuracy[87.50000000%]\n",
            "TEST BATCH 67/758====>test loss[0.12482732] | test accuracy[81.25000000%]\n",
            "TEST BATCH 68/758====>test loss[0.12424307] | test accuracy[87.50000000%]\n",
            "TEST BATCH 69/758====>test loss[0.12424954] | test accuracy[87.50000000%]\n",
            "TEST BATCH 70/758====>test loss[0.12435049] | test accuracy[87.50000000%]\n",
            "TEST BATCH 71/758====>test loss[0.12449526] | test accuracy[75.00000000%]\n",
            "TEST BATCH 72/758====>test loss[0.12304958] | test accuracy[93.75000000%]\n",
            "TEST BATCH 73/758====>test loss[0.12175551] | test accuracy[100.00000000%]\n",
            "TEST BATCH 74/758====>test loss[0.12112765] | test accuracy[87.50000000%]\n",
            "TEST BATCH 75/758====>test loss[0.12073186] | test accuracy[87.50000000%]\n",
            "TEST BATCH 76/758====>test loss[0.12134012] | test accuracy[68.75000000%]\n",
            "TEST BATCH 77/758====>test loss[0.12133342] | test accuracy[81.25000000%]\n",
            "TEST BATCH 78/758====>test loss[0.12093920] | test accuracy[87.50000000%]\n",
            "TEST BATCH 79/758====>test loss[0.12297557] | test accuracy[68.75000000%]\n",
            "TEST BATCH 80/758====>test loss[0.12212576] | test accuracy[93.75000000%]\n",
            "TEST BATCH 81/758====>test loss[0.12134376] | test accuracy[93.75000000%]\n",
            "TEST BATCH 82/758====>test loss[0.12040843] | test accuracy[93.75000000%]\n",
            "TEST BATCH 83/758====>test loss[0.12156047] | test accuracy[68.75000000%]\n",
            "TEST BATCH 84/758====>test loss[0.12315053] | test accuracy[68.75000000%]\n",
            "TEST BATCH 85/758====>test loss[0.12435106] | test accuracy[75.00000000%]\n",
            "TEST BATCH 86/758====>test loss[0.12487109] | test accuracy[81.25000000%]\n",
            "TEST BATCH 87/758====>test loss[0.12448146] | test accuracy[87.50000000%]\n",
            "TEST BATCH 88/758====>test loss[0.12484867] | test accuracy[81.25000000%]\n",
            "TEST BATCH 89/758====>test loss[0.12798735] | test accuracy[56.25000000%]\n",
            "TEST BATCH 90/758====>test loss[0.13040425] | test accuracy[56.25000000%]\n",
            "TEST BATCH 91/758====>test loss[0.13181495] | test accuracy[56.25000000%]\n",
            "TEST BATCH 92/758====>test loss[0.13106992] | test accuracy[87.50000000%]\n",
            "TEST BATCH 93/758====>test loss[0.13136832] | test accuracy[81.25000000%]\n",
            "TEST BATCH 94/758====>test loss[0.13114497] | test accuracy[87.50000000%]\n",
            "TEST BATCH 95/758====>test loss[0.13142291] | test accuracy[75.00000000%]\n",
            "TEST BATCH 96/758====>test loss[0.13280473] | test accuracy[62.50000000%]\n",
            "TEST BATCH 97/758====>test loss[0.13292515] | test accuracy[87.50000000%]\n",
            "TEST BATCH 98/758====>test loss[0.13369869] | test accuracy[68.75000000%]\n",
            "TEST BATCH 99/758====>test loss[0.13480813] | test accuracy[68.75000000%]\n",
            "TEST BATCH 100/758====>test loss[0.13394508] | test accuracy[93.75000000%]\n",
            "TEST BATCH 101/758====>test loss[0.13271392] | test accuracy[100.00000000%]\n",
            "TEST BATCH 102/758====>test loss[0.13187553] | test accuracy[93.75000000%]\n",
            "TEST BATCH 103/758====>test loss[0.13118384] | test accuracy[93.75000000%]\n",
            "TEST BATCH 104/758====>test loss[0.13057802] | test accuracy[87.50000000%]\n",
            "TEST BATCH 105/758====>test loss[0.13109462] | test accuracy[75.00000000%]\n",
            "TEST BATCH 106/758====>test loss[0.13060990] | test accuracy[81.25000000%]\n",
            "TEST BATCH 107/758====>test loss[0.13104705] | test accuracy[75.00000000%]\n",
            "TEST BATCH 108/758====>test loss[0.13095196] | test accuracy[81.25000000%]\n",
            "TEST BATCH 109/758====>test loss[0.13008830] | test accuracy[93.75000000%]\n",
            "TEST BATCH 110/758====>test loss[0.13100348] | test accuracy[75.00000000%]\n",
            "TEST BATCH 111/758====>test loss[0.13177992] | test accuracy[68.75000000%]\n",
            "TEST BATCH 112/758====>test loss[0.13214762] | test accuracy[68.75000000%]\n",
            "TEST BATCH 113/758====>test loss[0.13364852] | test accuracy[62.50000000%]\n",
            "TEST BATCH 114/758====>test loss[0.13343914] | test accuracy[81.25000000%]\n",
            "TEST BATCH 115/758====>test loss[0.13287189] | test accuracy[93.75000000%]\n",
            "TEST BATCH 116/758====>test loss[0.13213730] | test accuracy[93.75000000%]\n",
            "TEST BATCH 117/758====>test loss[0.13334468] | test accuracy[62.50000000%]\n",
            "TEST BATCH 118/758====>test loss[0.13306603] | test accuracy[93.75000000%]\n",
            "TEST BATCH 119/758====>test loss[0.13270775] | test accuracy[87.50000000%]\n",
            "TEST BATCH 120/758====>test loss[0.13370824] | test accuracy[68.75000000%]\n",
            "TEST BATCH 121/758====>test loss[0.13400767] | test accuracy[81.25000000%]\n",
            "TEST BATCH 122/758====>test loss[0.13394790] | test accuracy[87.50000000%]\n",
            "TEST BATCH 123/758====>test loss[0.13365667] | test accuracy[87.50000000%]\n",
            "TEST BATCH 124/758====>test loss[0.13492218] | test accuracy[62.50000000%]\n",
            "TEST BATCH 125/758====>test loss[0.13787746] | test accuracy[31.25000000%]\n",
            "TEST BATCH 126/758====>test loss[0.14107062] | test accuracy[37.50000000%]\n",
            "TEST BATCH 127/758====>test loss[0.14200396] | test accuracy[56.25000000%]\n",
            "TEST BATCH 128/758====>test loss[0.14192970] | test accuracy[87.50000000%]\n",
            "TEST BATCH 129/758====>test loss[0.14140279] | test accuracy[87.50000000%]\n",
            "TEST BATCH 130/758====>test loss[0.14111459] | test accuracy[87.50000000%]\n",
            "TEST BATCH 131/758====>test loss[0.14110358] | test accuracy[75.00000000%]\n",
            "TEST BATCH 132/758====>test loss[0.14298706] | test accuracy[50.00000000%]\n",
            "TEST BATCH 133/758====>test loss[0.14470263] | test accuracy[50.00000000%]\n",
            "TEST BATCH 134/758====>test loss[0.14497856] | test accuracy[75.00000000%]\n",
            "TEST BATCH 135/758====>test loss[0.14521202] | test accuracy[81.25000000%]\n",
            "TEST BATCH 136/758====>test loss[0.14500985] | test accuracy[87.50000000%]\n",
            "TEST BATCH 137/758====>test loss[0.14706346] | test accuracy[56.25000000%]\n",
            "TEST BATCH 138/758====>test loss[0.14714366] | test accuracy[81.25000000%]\n",
            "TEST BATCH 139/758====>test loss[0.14814127] | test accuracy[62.50000000%]\n",
            "TEST BATCH 140/758====>test loss[0.15004456] | test accuracy[50.00000000%]\n",
            "TEST BATCH 141/758====>test loss[0.14967177] | test accuracy[81.25000000%]\n",
            "TEST BATCH 142/758====>test loss[0.14951536] | test accuracy[87.50000000%]\n",
            "TEST BATCH 143/758====>test loss[0.14932969] | test accuracy[81.25000000%]\n",
            "TEST BATCH 144/758====>test loss[0.14908966] | test accuracy[87.50000000%]\n",
            "TEST BATCH 145/758====>test loss[0.14987854] | test accuracy[62.50000000%]\n",
            "TEST BATCH 146/758====>test loss[0.15090482] | test accuracy[62.50000000%]\n",
            "TEST BATCH 147/758====>test loss[0.15100306] | test accuracy[75.00000000%]\n",
            "TEST BATCH 148/758====>test loss[0.15295662] | test accuracy[50.00000000%]\n",
            "TEST BATCH 149/758====>test loss[0.15356171] | test accuracy[62.50000000%]\n",
            "TEST BATCH 150/758====>test loss[0.15310816] | test accuracy[81.25000000%]\n",
            "TEST BATCH 151/758====>test loss[0.15273661] | test accuracy[81.25000000%]\n",
            "TEST BATCH 152/758====>test loss[0.15270053] | test accuracy[87.50000000%]\n",
            "TEST BATCH 153/758====>test loss[0.15237599] | test accuracy[81.25000000%]\n",
            "TEST BATCH 154/758====>test loss[0.15277084] | test accuracy[75.00000000%]\n",
            "TEST BATCH 155/758====>test loss[0.15284556] | test accuracy[81.25000000%]\n",
            "TEST BATCH 156/758====>test loss[0.15278643] | test accuracy[75.00000000%]\n",
            "TEST BATCH 157/758====>test loss[0.15281860] | test accuracy[87.50000000%]\n",
            "TEST BATCH 158/758====>test loss[0.15260180] | test accuracy[81.25000000%]\n",
            "TEST BATCH 159/758====>test loss[0.15187087] | test accuracy[93.75000000%]\n",
            "TEST BATCH 160/758====>test loss[0.15106463] | test accuracy[100.00000000%]\n",
            "TEST BATCH 161/758====>test loss[0.15070297] | test accuracy[81.25000000%]\n",
            "TEST BATCH 162/758====>test loss[0.15042868] | test accuracy[87.50000000%]\n",
            "TEST BATCH 163/758====>test loss[0.15104195] | test accuracy[62.50000000%]\n",
            "TEST BATCH 164/758====>test loss[0.15078923] | test accuracy[87.50000000%]\n",
            "TEST BATCH 165/758====>test loss[0.15040560] | test accuracy[87.50000000%]\n",
            "TEST BATCH 166/758====>test loss[0.15117569] | test accuracy[62.50000000%]\n",
            "TEST BATCH 167/758====>test loss[0.15040364] | test accuracy[100.00000000%]\n",
            "TEST BATCH 168/758====>test loss[0.15062106] | test accuracy[81.25000000%]\n",
            "TEST BATCH 169/758====>test loss[0.15015662] | test accuracy[81.25000000%]\n",
            "TEST BATCH 170/758====>test loss[0.14978883] | test accuracy[93.75000000%]\n",
            "TEST BATCH 171/758====>test loss[0.14994133] | test accuracy[81.25000000%]\n",
            "TEST BATCH 172/758====>test loss[0.14922787] | test accuracy[100.00000000%]\n",
            "TEST BATCH 173/758====>test loss[0.15019456] | test accuracy[68.75000000%]\n",
            "TEST BATCH 174/758====>test loss[0.14987996] | test accuracy[81.25000000%]\n",
            "TEST BATCH 175/758====>test loss[0.15044682] | test accuracy[68.75000000%]\n",
            "TEST BATCH 176/758====>test loss[0.14983677] | test accuracy[93.75000000%]\n",
            "TEST BATCH 177/758====>test loss[0.14977146] | test accuracy[75.00000000%]\n",
            "TEST BATCH 178/758====>test loss[0.14937455] | test accuracy[93.75000000%]\n",
            "TEST BATCH 179/758====>test loss[0.14884183] | test accuracy[87.50000000%]\n",
            "TEST BATCH 180/758====>test loss[0.14833418] | test accuracy[87.50000000%]\n",
            "TEST BATCH 181/758====>test loss[0.14767505] | test accuracy[93.75000000%]\n",
            "TEST BATCH 182/758====>test loss[0.14689717] | test accuracy[100.00000000%]\n",
            "TEST BATCH 183/758====>test loss[0.14710196] | test accuracy[81.25000000%]\n",
            "TEST BATCH 184/758====>test loss[0.14805781] | test accuracy[68.75000000%]\n",
            "TEST BATCH 185/758====>test loss[0.14853485] | test accuracy[81.25000000%]\n",
            "TEST BATCH 186/758====>test loss[0.14826677] | test accuracy[87.50000000%]\n",
            "TEST BATCH 187/758====>test loss[0.14914596] | test accuracy[68.75000000%]\n",
            "TEST BATCH 188/758====>test loss[0.14883208] | test accuracy[93.75000000%]\n",
            "TEST BATCH 189/758====>test loss[0.15031732] | test accuracy[56.25000000%]\n",
            "TEST BATCH 190/758====>test loss[0.15024594] | test accuracy[87.50000000%]\n",
            "TEST BATCH 191/758====>test loss[0.15158607] | test accuracy[50.00000000%]\n",
            "TEST BATCH 192/758====>test loss[0.15147744] | test accuracy[87.50000000%]\n",
            "TEST BATCH 193/758====>test loss[0.15137100] | test accuracy[87.50000000%]\n",
            "TEST BATCH 194/758====>test loss[0.15134740] | test accuracy[75.00000000%]\n",
            "TEST BATCH 195/758====>test loss[0.15161702] | test accuracy[75.00000000%]\n",
            "TEST BATCH 196/758====>test loss[0.15186112] | test accuracy[75.00000000%]\n",
            "TEST BATCH 197/758====>test loss[0.15162789] | test accuracy[87.50000000%]\n",
            "TEST BATCH 198/758====>test loss[0.15218248] | test accuracy[68.75000000%]\n",
            "TEST BATCH 199/758====>test loss[0.15283490] | test accuracy[56.25000000%]\n",
            "TEST BATCH 200/758====>test loss[0.15262069] | test accuracy[87.50000000%]\n",
            "TEST BATCH 201/758====>test loss[0.15245466] | test accuracy[87.50000000%]\n",
            "TEST BATCH 202/758====>test loss[0.15208818] | test accuracy[81.25000000%]\n",
            "TEST BATCH 203/758====>test loss[0.15227676] | test accuracy[75.00000000%]\n",
            "TEST BATCH 204/758====>test loss[0.15286099] | test accuracy[62.50000000%]\n",
            "TEST BATCH 205/758====>test loss[0.15235336] | test accuracy[93.75000000%]\n",
            "TEST BATCH 206/758====>test loss[0.15202824] | test accuracy[87.50000000%]\n",
            "TEST BATCH 207/758====>test loss[0.15164320] | test accuracy[93.75000000%]\n",
            "TEST BATCH 208/758====>test loss[0.15210468] | test accuracy[56.25000000%]\n",
            "TEST BATCH 209/758====>test loss[0.15211696] | test accuracy[81.25000000%]\n",
            "TEST BATCH 210/758====>test loss[0.15286038] | test accuracy[56.25000000%]\n",
            "TEST BATCH 211/758====>test loss[0.15312219] | test accuracy[68.75000000%]\n",
            "TEST BATCH 212/758====>test loss[0.15297789] | test accuracy[87.50000000%]\n",
            "TEST BATCH 213/758====>test loss[0.15395013] | test accuracy[62.50000000%]\n",
            "TEST BATCH 214/758====>test loss[0.15393828] | test accuracy[81.25000000%]\n",
            "TEST BATCH 215/758====>test loss[0.15448655] | test accuracy[56.25000000%]\n",
            "TEST BATCH 216/758====>test loss[0.15464948] | test accuracy[75.00000000%]\n",
            "TEST BATCH 217/758====>test loss[0.15474695] | test accuracy[81.25000000%]\n",
            "TEST BATCH 218/758====>test loss[0.15463755] | test accuracy[87.50000000%]\n",
            "TEST BATCH 219/758====>test loss[0.15490891] | test accuracy[75.00000000%]\n",
            "TEST BATCH 220/758====>test loss[0.15482145] | test accuracy[81.25000000%]\n",
            "TEST BATCH 221/758====>test loss[0.15505807] | test accuracy[62.50000000%]\n",
            "TEST BATCH 222/758====>test loss[0.15523279] | test accuracy[75.00000000%]\n",
            "TEST BATCH 223/758====>test loss[0.15478666] | test accuracy[93.75000000%]\n",
            "TEST BATCH 224/758====>test loss[0.15418714] | test accuracy[100.00000000%]\n",
            "TEST BATCH 225/758====>test loss[0.15378017] | test accuracy[87.50000000%]\n",
            "TEST BATCH 226/758====>test loss[0.15351107] | test accuracy[87.50000000%]\n",
            "TEST BATCH 227/758====>test loss[0.15342062] | test accuracy[68.75000000%]\n",
            "TEST BATCH 228/758====>test loss[0.15357024] | test accuracy[62.50000000%]\n",
            "TEST BATCH 229/758====>test loss[0.15345212] | test accuracy[75.00000000%]\n",
            "TEST BATCH 230/758====>test loss[0.15319905] | test accuracy[87.50000000%]\n",
            "TEST BATCH 231/758====>test loss[0.15419226] | test accuracy[56.25000000%]\n",
            "TEST BATCH 232/758====>test loss[0.15452027] | test accuracy[68.75000000%]\n",
            "TEST BATCH 233/758====>test loss[0.15489690] | test accuracy[75.00000000%]\n",
            "TEST BATCH 234/758====>test loss[0.15570973] | test accuracy[56.25000000%]\n",
            "TEST BATCH 235/758====>test loss[0.15636500] | test accuracy[62.50000000%]\n",
            "TEST BATCH 236/758====>test loss[0.15593885] | test accuracy[93.75000000%]\n",
            "TEST BATCH 237/758====>test loss[0.15564630] | test accuracy[87.50000000%]\n",
            "TEST BATCH 238/758====>test loss[0.15586616] | test accuracy[68.75000000%]\n",
            "TEST BATCH 239/758====>test loss[0.15577215] | test accuracy[81.25000000%]\n",
            "TEST BATCH 240/758====>test loss[0.15547875] | test accuracy[93.75000000%]\n",
            "TEST BATCH 241/758====>test loss[0.15575594] | test accuracy[68.75000000%]\n",
            "TEST BATCH 242/758====>test loss[0.15573679] | test accuracy[81.25000000%]\n",
            "TEST BATCH 243/758====>test loss[0.15611024] | test accuracy[75.00000000%]\n",
            "TEST BATCH 244/758====>test loss[0.15648975] | test accuracy[68.75000000%]\n",
            "TEST BATCH 245/758====>test loss[0.15595836] | test accuracy[93.75000000%]\n",
            "TEST BATCH 246/758====>test loss[0.15650650] | test accuracy[43.75000000%]\n",
            "TEST BATCH 247/758====>test loss[0.15593483] | test accuracy[100.00000000%]\n",
            "TEST BATCH 248/758====>test loss[0.15667853] | test accuracy[56.25000000%]\n",
            "TEST BATCH 249/758====>test loss[0.15675222] | test accuracy[81.25000000%]\n",
            "TEST BATCH 250/758====>test loss[0.15700836] | test accuracy[75.00000000%]\n",
            "TEST BATCH 251/758====>test loss[0.15694375] | test accuracy[81.25000000%]\n",
            "TEST BATCH 252/758====>test loss[0.15737423] | test accuracy[43.75000000%]\n",
            "TEST BATCH 253/758====>test loss[0.15714576] | test accuracy[87.50000000%]\n",
            "TEST BATCH 254/758====>test loss[0.15685611] | test accuracy[87.50000000%]\n",
            "TEST BATCH 255/758====>test loss[0.15704107] | test accuracy[75.00000000%]\n",
            "TEST BATCH 256/758====>test loss[0.15738083] | test accuracy[62.50000000%]\n",
            "TEST BATCH 257/758====>test loss[0.15717902] | test accuracy[81.25000000%]\n",
            "TEST BATCH 258/758====>test loss[0.15721616] | test accuracy[81.25000000%]\n",
            "TEST BATCH 259/758====>test loss[0.15713662] | test accuracy[87.50000000%]\n",
            "TEST BATCH 260/758====>test loss[0.15811445] | test accuracy[56.25000000%]\n",
            "TEST BATCH 261/758====>test loss[0.15811475] | test accuracy[81.25000000%]\n",
            "TEST BATCH 262/758====>test loss[0.15810725] | test accuracy[81.25000000%]\n",
            "TEST BATCH 263/758====>test loss[0.15817347] | test accuracy[81.25000000%]\n",
            "TEST BATCH 264/758====>test loss[0.15760882] | test accuracy[100.00000000%]\n",
            "TEST BATCH 265/758====>test loss[0.15786932] | test accuracy[75.00000000%]\n",
            "TEST BATCH 266/758====>test loss[0.15871189] | test accuracy[56.25000000%]\n",
            "TEST BATCH 267/758====>test loss[0.15866509] | test accuracy[75.00000000%]\n",
            "TEST BATCH 268/758====>test loss[0.15963453] | test accuracy[43.75000000%]\n",
            "TEST BATCH 269/758====>test loss[0.15938604] | test accuracy[87.50000000%]\n",
            "TEST BATCH 270/758====>test loss[0.16041248] | test accuracy[50.00000000%]\n",
            "TEST BATCH 271/758====>test loss[0.16084646] | test accuracy[68.75000000%]\n",
            "TEST BATCH 272/758====>test loss[0.16093089] | test accuracy[81.25000000%]\n",
            "TEST BATCH 273/758====>test loss[0.16087517] | test accuracy[81.25000000%]\n",
            "TEST BATCH 274/758====>test loss[0.16118465] | test accuracy[75.00000000%]\n",
            "TEST BATCH 275/758====>test loss[0.16089075] | test accuracy[87.50000000%]\n",
            "TEST BATCH 276/758====>test loss[0.16078629] | test accuracy[75.00000000%]\n",
            "TEST BATCH 277/758====>test loss[0.16077145] | test accuracy[75.00000000%]\n",
            "TEST BATCH 278/758====>test loss[0.16060420] | test accuracy[81.25000000%]\n",
            "TEST BATCH 279/758====>test loss[0.16055848] | test accuracy[87.50000000%]\n",
            "TEST BATCH 280/758====>test loss[0.16040004] | test accuracy[81.25000000%]\n",
            "TEST BATCH 281/758====>test loss[0.16032705] | test accuracy[75.00000000%]\n",
            "TEST BATCH 282/758====>test loss[0.16105105] | test accuracy[68.75000000%]\n",
            "TEST BATCH 283/758====>test loss[0.16186407] | test accuracy[43.75000000%]\n",
            "TEST BATCH 284/758====>test loss[0.16311119] | test accuracy[37.50000000%]\n",
            "TEST BATCH 285/758====>test loss[0.16371485] | test accuracy[50.00000000%]\n",
            "TEST BATCH 286/758====>test loss[0.16406745] | test accuracy[68.75000000%]\n",
            "TEST BATCH 287/758====>test loss[0.16427320] | test accuracy[75.00000000%]\n",
            "TEST BATCH 288/758====>test loss[0.16416392] | test accuracy[81.25000000%]\n",
            "TEST BATCH 289/758====>test loss[0.16463402] | test accuracy[68.75000000%]\n",
            "TEST BATCH 290/758====>test loss[0.16416502] | test accuracy[100.00000000%]\n",
            "TEST BATCH 291/758====>test loss[0.16377670] | test accuracy[93.75000000%]\n",
            "TEST BATCH 292/758====>test loss[0.16383952] | test accuracy[81.25000000%]\n",
            "TEST BATCH 293/758====>test loss[0.16381981] | test accuracy[75.00000000%]\n",
            "TEST BATCH 294/758====>test loss[0.16404044] | test accuracy[68.75000000%]\n",
            "TEST BATCH 295/758====>test loss[0.16402084] | test accuracy[87.50000000%]\n",
            "TEST BATCH 296/758====>test loss[0.16375752] | test accuracy[93.75000000%]\n",
            "TEST BATCH 297/758====>test loss[0.16410802] | test accuracy[62.50000000%]\n",
            "TEST BATCH 298/758====>test loss[0.16467551] | test accuracy[56.25000000%]\n",
            "TEST BATCH 299/758====>test loss[0.16423894] | test accuracy[93.75000000%]\n",
            "TEST BATCH 300/758====>test loss[0.16424473] | test accuracy[75.00000000%]\n",
            "TEST BATCH 301/758====>test loss[0.16392703] | test accuracy[93.75000000%]\n",
            "TEST BATCH 302/758====>test loss[0.16422411] | test accuracy[68.75000000%]\n",
            "TEST BATCH 303/758====>test loss[0.16407954] | test accuracy[81.25000000%]\n",
            "TEST BATCH 304/758====>test loss[0.16397988] | test accuracy[81.25000000%]\n",
            "TEST BATCH 305/758====>test loss[0.16392951] | test accuracy[81.25000000%]\n",
            "TEST BATCH 306/758====>test loss[0.16429966] | test accuracy[62.50000000%]\n",
            "TEST BATCH 307/758====>test loss[0.16417374] | test accuracy[87.50000000%]\n",
            "TEST BATCH 308/758====>test loss[0.16390459] | test accuracy[93.75000000%]\n",
            "TEST BATCH 309/758====>test loss[0.16376092] | test accuracy[81.25000000%]\n",
            "TEST BATCH 310/758====>test loss[0.16373391] | test accuracy[81.25000000%]\n",
            "TEST BATCH 311/758====>test loss[0.16356123] | test accuracy[87.50000000%]\n",
            "TEST BATCH 312/758====>test loss[0.16318700] | test accuracy[87.50000000%]\n",
            "TEST BATCH 313/758====>test loss[0.16331904] | test accuracy[62.50000000%]\n",
            "TEST BATCH 314/758====>test loss[0.16322928] | test accuracy[81.25000000%]\n",
            "TEST BATCH 315/758====>test loss[0.16280873] | test accuracy[100.00000000%]\n",
            "TEST BATCH 316/758====>test loss[0.16255206] | test accuracy[93.75000000%]\n",
            "TEST BATCH 317/758====>test loss[0.16234785] | test accuracy[81.25000000%]\n",
            "TEST BATCH 318/758====>test loss[0.16291326] | test accuracy[68.75000000%]\n",
            "TEST BATCH 319/758====>test loss[0.16327205] | test accuracy[62.50000000%]\n",
            "TEST BATCH 320/758====>test loss[0.16352852] | test accuracy[62.50000000%]\n",
            "TEST BATCH 321/758====>test loss[0.16329785] | test accuracy[87.50000000%]\n",
            "TEST BATCH 322/758====>test loss[0.16338030] | test accuracy[81.25000000%]\n",
            "TEST BATCH 323/758====>test loss[0.16315302] | test accuracy[93.75000000%]\n",
            "TEST BATCH 324/758====>test loss[0.16295161] | test accuracy[87.50000000%]\n",
            "TEST BATCH 325/758====>test loss[0.16316445] | test accuracy[75.00000000%]\n",
            "TEST BATCH 326/758====>test loss[0.16295708] | test accuracy[87.50000000%]\n",
            "TEST BATCH 327/758====>test loss[0.16263703] | test accuracy[87.50000000%]\n",
            "TEST BATCH 328/758====>test loss[0.16267594] | test accuracy[81.25000000%]\n",
            "TEST BATCH 329/758====>test loss[0.16272976] | test accuracy[75.00000000%]\n",
            "TEST BATCH 330/758====>test loss[0.16240844] | test accuracy[93.75000000%]\n",
            "TEST BATCH 331/758====>test loss[0.16213949] | test accuracy[87.50000000%]\n",
            "TEST BATCH 332/758====>test loss[0.16248795] | test accuracy[75.00000000%]\n",
            "TEST BATCH 333/758====>test loss[0.16235058] | test accuracy[87.50000000%]\n",
            "TEST BATCH 334/758====>test loss[0.16201890] | test accuracy[93.75000000%]\n",
            "TEST BATCH 335/758====>test loss[0.16215358] | test accuracy[75.00000000%]\n",
            "TEST BATCH 336/758====>test loss[0.16190170] | test accuracy[93.75000000%]\n",
            "TEST BATCH 337/758====>test loss[0.16189310] | test accuracy[75.00000000%]\n",
            "TEST BATCH 338/758====>test loss[0.16215825] | test accuracy[68.75000000%]\n",
            "TEST BATCH 339/758====>test loss[0.16210630] | test accuracy[81.25000000%]\n",
            "TEST BATCH 340/758====>test loss[0.16191818] | test accuracy[87.50000000%]\n",
            "TEST BATCH 341/758====>test loss[0.16190997] | test accuracy[75.00000000%]\n",
            "TEST BATCH 342/758====>test loss[0.16210116] | test accuracy[75.00000000%]\n",
            "TEST BATCH 343/758====>test loss[0.16184422] | test accuracy[87.50000000%]\n",
            "TEST BATCH 344/758====>test loss[0.16187783] | test accuracy[81.25000000%]\n",
            "TEST BATCH 345/758====>test loss[0.16176593] | test accuracy[81.25000000%]\n",
            "TEST BATCH 346/758====>test loss[0.16171914] | test accuracy[81.25000000%]\n",
            "TEST BATCH 347/758====>test loss[0.16177936] | test accuracy[68.75000000%]\n",
            "TEST BATCH 348/758====>test loss[0.16169653] | test accuracy[81.25000000%]\n",
            "TEST BATCH 349/758====>test loss[0.16134841] | test accuracy[93.75000000%]\n",
            "TEST BATCH 350/758====>test loss[0.16148810] | test accuracy[75.00000000%]\n",
            "TEST BATCH 351/758====>test loss[0.16152695] | test accuracy[75.00000000%]\n",
            "TEST BATCH 352/758====>test loss[0.16168863] | test accuracy[75.00000000%]\n",
            "TEST BATCH 353/758====>test loss[0.16166985] | test accuracy[81.25000000%]\n",
            "TEST BATCH 354/758====>test loss[0.16211293] | test accuracy[56.25000000%]\n",
            "TEST BATCH 355/758====>test loss[0.16204634] | test accuracy[87.50000000%]\n",
            "TEST BATCH 356/758====>test loss[0.16226937] | test accuracy[68.75000000%]\n",
            "TEST BATCH 357/758====>test loss[0.16230003] | test accuracy[75.00000000%]\n",
            "TEST BATCH 358/758====>test loss[0.16244512] | test accuracy[68.75000000%]\n",
            "TEST BATCH 359/758====>test loss[0.16377324] | test accuracy[31.25000000%]\n",
            "TEST BATCH 360/758====>test loss[0.16378651] | test accuracy[81.25000000%]\n",
            "TEST BATCH 361/758====>test loss[0.16365849] | test accuracy[87.50000000%]\n",
            "TEST BATCH 362/758====>test loss[0.16332085] | test accuracy[93.75000000%]\n",
            "TEST BATCH 363/758====>test loss[0.16308503] | test accuracy[87.50000000%]\n",
            "TEST BATCH 364/758====>test loss[0.16323448] | test accuracy[75.00000000%]\n",
            "TEST BATCH 365/758====>test loss[0.16346562] | test accuracy[75.00000000%]\n",
            "TEST BATCH 366/758====>test loss[0.16392694] | test accuracy[68.75000000%]\n",
            "TEST BATCH 367/758====>test loss[0.16474223] | test accuracy[50.00000000%]\n",
            "TEST BATCH 368/758====>test loss[0.16487395] | test accuracy[81.25000000%]\n",
            "TEST BATCH 369/758====>test loss[0.16498247] | test accuracy[68.75000000%]\n",
            "TEST BATCH 370/758====>test loss[0.16532294] | test accuracy[75.00000000%]\n",
            "TEST BATCH 371/758====>test loss[0.16522615] | test accuracy[81.25000000%]\n",
            "TEST BATCH 372/758====>test loss[0.16485354] | test accuracy[93.75000000%]\n",
            "TEST BATCH 373/758====>test loss[0.16497154] | test accuracy[81.25000000%]\n",
            "TEST BATCH 374/758====>test loss[0.16484905] | test accuracy[87.50000000%]\n",
            "TEST BATCH 375/758====>test loss[0.16524518] | test accuracy[68.75000000%]\n",
            "TEST BATCH 376/758====>test loss[0.16526362] | test accuracy[81.25000000%]\n",
            "TEST BATCH 377/758====>test loss[0.16526985] | test accuracy[68.75000000%]\n",
            "TEST BATCH 378/758====>test loss[0.16576537] | test accuracy[56.25000000%]\n",
            "TEST BATCH 379/758====>test loss[0.16588403] | test accuracy[81.25000000%]\n",
            "TEST BATCH 380/758====>test loss[0.16597431] | test accuracy[68.75000000%]\n",
            "TEST BATCH 381/758====>test loss[0.16624000] | test accuracy[56.25000000%]\n",
            "TEST BATCH 382/758====>test loss[0.16664768] | test accuracy[50.00000000%]\n",
            "TEST BATCH 383/758====>test loss[0.16714778] | test accuracy[68.75000000%]\n",
            "TEST BATCH 384/758====>test loss[0.16794622] | test accuracy[43.75000000%]\n",
            "TEST BATCH 385/758====>test loss[0.16796890] | test accuracy[81.25000000%]\n",
            "TEST BATCH 386/758====>test loss[0.16756588] | test accuracy[100.00000000%]\n",
            "TEST BATCH 387/758====>test loss[0.16725073] | test accuracy[93.75000000%]\n",
            "TEST BATCH 388/758====>test loss[0.16702450] | test accuracy[93.75000000%]\n",
            "TEST BATCH 389/758====>test loss[0.16701568] | test accuracy[87.50000000%]\n",
            "TEST BATCH 390/758====>test loss[0.16691684] | test accuracy[75.00000000%]\n",
            "TEST BATCH 391/758====>test loss[0.16731655] | test accuracy[62.50000000%]\n",
            "TEST BATCH 392/758====>test loss[0.16760685] | test accuracy[75.00000000%]\n",
            "TEST BATCH 393/758====>test loss[0.16758707] | test accuracy[62.50000000%]\n",
            "TEST BATCH 394/758====>test loss[0.16775422] | test accuracy[75.00000000%]\n",
            "TEST BATCH 395/758====>test loss[0.16848219] | test accuracy[37.50000000%]\n",
            "TEST BATCH 396/758====>test loss[0.16847373] | test accuracy[87.50000000%]\n",
            "TEST BATCH 397/758====>test loss[0.16871279] | test accuracy[68.75000000%]\n",
            "TEST BATCH 398/758====>test loss[0.16865968] | test accuracy[81.25000000%]\n",
            "TEST BATCH 399/758====>test loss[0.16867973] | test accuracy[81.25000000%]\n",
            "TEST BATCH 400/758====>test loss[0.16877190] | test accuracy[68.75000000%]\n",
            "TEST BATCH 401/758====>test loss[0.16893362] | test accuracy[68.75000000%]\n",
            "TEST BATCH 402/758====>test loss[0.16907837] | test accuracy[68.75000000%]\n",
            "TEST BATCH 403/758====>test loss[0.16932331] | test accuracy[68.75000000%]\n",
            "TEST BATCH 404/758====>test loss[0.16982327] | test accuracy[62.50000000%]\n",
            "TEST BATCH 405/758====>test loss[0.17015217] | test accuracy[75.00000000%]\n",
            "TEST BATCH 406/758====>test loss[0.17053357] | test accuracy[62.50000000%]\n",
            "TEST BATCH 407/758====>test loss[0.17142277] | test accuracy[43.75000000%]\n",
            "TEST BATCH 408/758====>test loss[0.17191851] | test accuracy[62.50000000%]\n",
            "TEST BATCH 409/758====>test loss[0.17179688] | test accuracy[81.25000000%]\n",
            "TEST BATCH 410/758====>test loss[0.17226400] | test accuracy[62.50000000%]\n",
            "TEST BATCH 411/758====>test loss[0.17206833] | test accuracy[93.75000000%]\n",
            "TEST BATCH 412/758====>test loss[0.17217072] | test accuracy[75.00000000%]\n",
            "TEST BATCH 413/758====>test loss[0.17227562] | test accuracy[75.00000000%]\n",
            "TEST BATCH 414/758====>test loss[0.17259090] | test accuracy[75.00000000%]\n",
            "TEST BATCH 415/758====>test loss[0.17257473] | test accuracy[87.50000000%]\n",
            "TEST BATCH 416/758====>test loss[0.17260470] | test accuracy[81.25000000%]\n",
            "TEST BATCH 417/758====>test loss[0.17276750] | test accuracy[81.25000000%]\n",
            "TEST BATCH 418/758====>test loss[0.17282560] | test accuracy[68.75000000%]\n",
            "TEST BATCH 419/758====>test loss[0.17362845] | test accuracy[50.00000000%]\n",
            "TEST BATCH 420/758====>test loss[0.17371944] | test accuracy[68.75000000%]\n",
            "TEST BATCH 421/758====>test loss[0.17391311] | test accuracy[75.00000000%]\n",
            "TEST BATCH 422/758====>test loss[0.17387320] | test accuracy[81.25000000%]\n",
            "TEST BATCH 423/758====>test loss[0.17373181] | test accuracy[87.50000000%]\n",
            "TEST BATCH 424/758====>test loss[0.17359131] | test accuracy[87.50000000%]\n",
            "TEST BATCH 425/758====>test loss[0.17358154] | test accuracy[81.25000000%]\n",
            "TEST BATCH 426/758====>test loss[0.17352707] | test accuracy[87.50000000%]\n",
            "TEST BATCH 427/758====>test loss[0.17379230] | test accuracy[62.50000000%]\n",
            "TEST BATCH 428/758====>test loss[0.17385565] | test accuracy[81.25000000%]\n",
            "TEST BATCH 429/758====>test loss[0.17360522] | test accuracy[93.75000000%]\n",
            "TEST BATCH 430/758====>test loss[0.17337650] | test accuracy[87.50000000%]\n",
            "TEST BATCH 431/758====>test loss[0.17356391] | test accuracy[68.75000000%]\n",
            "TEST BATCH 432/758====>test loss[0.17343062] | test accuracy[87.50000000%]\n",
            "TEST BATCH 433/758====>test loss[0.17364490] | test accuracy[68.75000000%]\n",
            "TEST BATCH 434/758====>test loss[0.17358644] | test accuracy[81.25000000%]\n",
            "TEST BATCH 435/758====>test loss[0.17325875] | test accuracy[93.75000000%]\n",
            "TEST BATCH 436/758====>test loss[0.17312608] | test accuracy[87.50000000%]\n",
            "TEST BATCH 437/758====>test loss[0.17335364] | test accuracy[75.00000000%]\n",
            "TEST BATCH 438/758====>test loss[0.17316697] | test accuracy[87.50000000%]\n",
            "TEST BATCH 439/758====>test loss[0.17327898] | test accuracy[75.00000000%]\n",
            "TEST BATCH 440/758====>test loss[0.17291252] | test accuracy[100.00000000%]\n",
            "TEST BATCH 441/758====>test loss[0.17273554] | test accuracy[93.75000000%]\n",
            "TEST BATCH 442/758====>test loss[0.17245015] | test accuracy[93.75000000%]\n",
            "TEST BATCH 443/758====>test loss[0.17208379] | test accuracy[100.00000000%]\n",
            "TEST BATCH 444/758====>test loss[0.17179020] | test accuracy[93.75000000%]\n",
            "TEST BATCH 445/758====>test loss[0.17164588] | test accuracy[87.50000000%]\n",
            "TEST BATCH 446/758====>test loss[0.17141216] | test accuracy[87.50000000%]\n",
            "TEST BATCH 447/758====>test loss[0.17133143] | test accuracy[81.25000000%]\n",
            "TEST BATCH 448/758====>test loss[0.17132560] | test accuracy[81.25000000%]\n",
            "TEST BATCH 449/758====>test loss[0.17110759] | test accuracy[93.75000000%]\n",
            "TEST BATCH 450/758====>test loss[0.17113388] | test accuracy[81.25000000%]\n",
            "TEST BATCH 451/758====>test loss[0.17103089] | test accuracy[81.25000000%]\n",
            "TEST BATCH 452/758====>test loss[0.17096988] | test accuracy[81.25000000%]\n",
            "TEST BATCH 453/758====>test loss[0.17108703] | test accuracy[68.75000000%]\n",
            "TEST BATCH 454/758====>test loss[0.17078146] | test accuracy[93.75000000%]\n",
            "TEST BATCH 455/758====>test loss[0.17050170] | test accuracy[93.75000000%]\n",
            "TEST BATCH 456/758====>test loss[0.17046769] | test accuracy[87.50000000%]\n",
            "TEST BATCH 457/758====>test loss[0.17052629] | test accuracy[68.75000000%]\n",
            "TEST BATCH 458/758====>test loss[0.17054494] | test accuracy[81.25000000%]\n",
            "TEST BATCH 459/758====>test loss[0.17038241] | test accuracy[87.50000000%]\n",
            "TEST BATCH 460/758====>test loss[0.17008539] | test accuracy[93.75000000%]\n",
            "TEST BATCH 461/758====>test loss[0.17015752] | test accuracy[81.25000000%]\n",
            "TEST BATCH 462/758====>test loss[0.16980299] | test accuracy[100.00000000%]\n",
            "TEST BATCH 463/758====>test loss[0.16969319] | test accuracy[81.25000000%]\n",
            "TEST BATCH 464/758====>test loss[0.16939661] | test accuracy[93.75000000%]\n",
            "TEST BATCH 465/758====>test loss[0.16906270] | test accuracy[100.00000000%]\n",
            "TEST BATCH 466/758====>test loss[0.16918998] | test accuracy[68.75000000%]\n",
            "TEST BATCH 467/758====>test loss[0.16912512] | test accuracy[81.25000000%]\n",
            "TEST BATCH 468/758====>test loss[0.16912130] | test accuracy[75.00000000%]\n",
            "TEST BATCH 469/758====>test loss[0.16880248] | test accuracy[100.00000000%]\n",
            "TEST BATCH 470/758====>test loss[0.16868829] | test accuracy[81.25000000%]\n",
            "TEST BATCH 471/758====>test loss[0.16861017] | test accuracy[81.25000000%]\n",
            "TEST BATCH 472/758====>test loss[0.16838684] | test accuracy[93.75000000%]\n",
            "TEST BATCH 473/758====>test loss[0.16813449] | test accuracy[93.75000000%]\n",
            "TEST BATCH 474/758====>test loss[0.16782291] | test accuracy[93.75000000%]\n",
            "TEST BATCH 475/758====>test loss[0.16755626] | test accuracy[93.75000000%]\n",
            "TEST BATCH 476/758====>test loss[0.16764981] | test accuracy[75.00000000%]\n",
            "TEST BATCH 477/758====>test loss[0.16751353] | test accuracy[87.50000000%]\n",
            "TEST BATCH 478/758====>test loss[0.16758519] | test accuracy[68.75000000%]\n",
            "TEST BATCH 479/758====>test loss[0.16738124] | test accuracy[93.75000000%]\n",
            "TEST BATCH 480/758====>test loss[0.16707344] | test accuracy[93.75000000%]\n",
            "TEST BATCH 481/758====>test loss[0.16715012] | test accuracy[75.00000000%]\n",
            "TEST BATCH 482/758====>test loss[0.16696810] | test accuracy[87.50000000%]\n",
            "TEST BATCH 483/758====>test loss[0.16680328] | test accuracy[93.75000000%]\n",
            "TEST BATCH 484/758====>test loss[0.16674291] | test accuracy[75.00000000%]\n",
            "TEST BATCH 485/758====>test loss[0.16655359] | test accuracy[81.25000000%]\n",
            "TEST BATCH 486/758====>test loss[0.16637629] | test accuracy[93.75000000%]\n",
            "TEST BATCH 487/758====>test loss[0.16649734] | test accuracy[75.00000000%]\n",
            "TEST BATCH 488/758====>test loss[0.16634426] | test accuracy[93.75000000%]\n",
            "TEST BATCH 489/758====>test loss[0.16612799] | test accuracy[93.75000000%]\n",
            "TEST BATCH 490/758====>test loss[0.16613422] | test accuracy[81.25000000%]\n",
            "TEST BATCH 491/758====>test loss[0.16590625] | test accuracy[87.50000000%]\n",
            "TEST BATCH 492/758====>test loss[0.16571672] | test accuracy[93.75000000%]\n",
            "TEST BATCH 493/758====>test loss[0.16550328] | test accuracy[93.75000000%]\n",
            "TEST BATCH 494/758====>test loss[0.16562953] | test accuracy[75.00000000%]\n",
            "TEST BATCH 495/758====>test loss[0.16544067] | test accuracy[87.50000000%]\n",
            "TEST BATCH 496/758====>test loss[0.16521312] | test accuracy[93.75000000%]\n",
            "TEST BATCH 497/758====>test loss[0.16524670] | test accuracy[81.25000000%]\n",
            "TEST BATCH 498/758====>test loss[0.16517056] | test accuracy[81.25000000%]\n",
            "TEST BATCH 499/758====>test loss[0.16539846] | test accuracy[62.50000000%]\n",
            "TEST BATCH 500/758====>test loss[0.16545256] | test accuracy[68.75000000%]\n",
            "TEST BATCH 501/758====>test loss[0.16558544] | test accuracy[75.00000000%]\n",
            "TEST BATCH 502/758====>test loss[0.16569344] | test accuracy[68.75000000%]\n",
            "TEST BATCH 503/758====>test loss[0.16547508] | test accuracy[93.75000000%]\n",
            "TEST BATCH 504/758====>test loss[0.16520736] | test accuracy[93.75000000%]\n",
            "TEST BATCH 505/758====>test loss[0.16526764] | test accuracy[68.75000000%]\n",
            "TEST BATCH 506/758====>test loss[0.16517740] | test accuracy[87.50000000%]\n",
            "TEST BATCH 507/758====>test loss[0.16499260] | test accuracy[87.50000000%]\n",
            "TEST BATCH 508/758====>test loss[0.16471271] | test accuracy[100.00000000%]\n",
            "TEST BATCH 509/758====>test loss[0.16451452] | test accuracy[93.75000000%]\n",
            "TEST BATCH 510/758====>test loss[0.16440628] | test accuracy[87.50000000%]\n",
            "TEST BATCH 511/758====>test loss[0.16423222] | test accuracy[87.50000000%]\n",
            "TEST BATCH 512/758====>test loss[0.16396601] | test accuracy[93.75000000%]\n",
            "TEST BATCH 513/758====>test loss[0.16398508] | test accuracy[81.25000000%]\n",
            "TEST BATCH 514/758====>test loss[0.16398279] | test accuracy[68.75000000%]\n",
            "TEST BATCH 515/758====>test loss[0.16379378] | test accuracy[87.50000000%]\n",
            "TEST BATCH 516/758====>test loss[0.16358035] | test accuracy[93.75000000%]\n",
            "TEST BATCH 517/758====>test loss[0.16329098] | test accuracy[100.00000000%]\n",
            "TEST BATCH 518/758====>test loss[0.16348836] | test accuracy[68.75000000%]\n",
            "TEST BATCH 519/758====>test loss[0.16337266] | test accuracy[81.25000000%]\n",
            "TEST BATCH 520/758====>test loss[0.16341617] | test accuracy[81.25000000%]\n",
            "TEST BATCH 521/758====>test loss[0.16321759] | test accuracy[93.75000000%]\n",
            "TEST BATCH 522/758====>test loss[0.16325622] | test accuracy[75.00000000%]\n",
            "TEST BATCH 523/758====>test loss[0.16342119] | test accuracy[56.25000000%]\n",
            "TEST BATCH 524/758====>test loss[0.16325386] | test accuracy[93.75000000%]\n",
            "TEST BATCH 525/758====>test loss[0.16312532] | test accuracy[68.75000000%]\n",
            "TEST BATCH 526/758====>test loss[0.16302450] | test accuracy[87.50000000%]\n",
            "TEST BATCH 527/758====>test loss[0.16359342] | test accuracy[56.25000000%]\n",
            "TEST BATCH 528/758====>test loss[0.16379382] | test accuracy[75.00000000%]\n",
            "TEST BATCH 529/758====>test loss[0.16422571] | test accuracy[62.50000000%]\n",
            "TEST BATCH 530/758====>test loss[0.16398089] | test accuracy[93.75000000%]\n",
            "TEST BATCH 531/758====>test loss[0.16398873] | test accuracy[62.50000000%]\n",
            "TEST BATCH 532/758====>test loss[0.16369934] | test accuracy[100.00000000%]\n",
            "TEST BATCH 533/758====>test loss[0.16357473] | test accuracy[87.50000000%]\n",
            "TEST BATCH 534/758====>test loss[0.16328238] | test accuracy[100.00000000%]\n",
            "TEST BATCH 535/758====>test loss[0.16335389] | test accuracy[75.00000000%]\n",
            "TEST BATCH 536/758====>test loss[0.16310608] | test accuracy[100.00000000%]\n",
            "TEST BATCH 537/758====>test loss[0.16322197] | test accuracy[75.00000000%]\n",
            "TEST BATCH 538/758====>test loss[0.16409988] | test accuracy[37.50000000%]\n",
            "TEST BATCH 539/758====>test loss[0.16459868] | test accuracy[43.75000000%]\n",
            "TEST BATCH 540/758====>test loss[0.16479916] | test accuracy[68.75000000%]\n",
            "TEST BATCH 541/758====>test loss[0.16477886] | test accuracy[75.00000000%]\n",
            "TEST BATCH 542/758====>test loss[0.16452873] | test accuracy[93.75000000%]\n",
            "TEST BATCH 543/758====>test loss[0.16424171] | test accuracy[100.00000000%]\n",
            "TEST BATCH 544/758====>test loss[0.16421654] | test accuracy[81.25000000%]\n",
            "TEST BATCH 545/758====>test loss[0.16398981] | test accuracy[93.75000000%]\n",
            "TEST BATCH 546/758====>test loss[0.16375218] | test accuracy[93.75000000%]\n",
            "TEST BATCH 547/758====>test loss[0.16369843] | test accuracy[81.25000000%]\n",
            "TEST BATCH 548/758====>test loss[0.16341459] | test accuracy[100.00000000%]\n",
            "TEST BATCH 549/758====>test loss[0.16319482] | test accuracy[93.75000000%]\n",
            "TEST BATCH 550/758====>test loss[0.16293762] | test accuracy[93.75000000%]\n",
            "TEST BATCH 551/758====>test loss[0.16335018] | test accuracy[62.50000000%]\n",
            "TEST BATCH 552/758====>test loss[0.16387533] | test accuracy[50.00000000%]\n",
            "TEST BATCH 553/758====>test loss[0.16377716] | test accuracy[87.50000000%]\n",
            "TEST BATCH 554/758====>test loss[0.16350113] | test accuracy[100.00000000%]\n",
            "TEST BATCH 555/758====>test loss[0.16342825] | test accuracy[87.50000000%]\n",
            "TEST BATCH 556/758====>test loss[0.16349212] | test accuracy[50.00000000%]\n",
            "TEST BATCH 557/758====>test loss[0.16321288] | test accuracy[100.00000000%]\n",
            "TEST BATCH 558/758====>test loss[0.16308156] | test accuracy[87.50000000%]\n",
            "TEST BATCH 559/758====>test loss[0.16315537] | test accuracy[81.25000000%]\n",
            "TEST BATCH 560/758====>test loss[0.16321277] | test accuracy[75.00000000%]\n",
            "TEST BATCH 561/758====>test loss[0.16335789] | test accuracy[75.00000000%]\n",
            "TEST BATCH 562/758====>test loss[0.16359302] | test accuracy[68.75000000%]\n",
            "TEST BATCH 563/758====>test loss[0.16362197] | test accuracy[81.25000000%]\n",
            "TEST BATCH 564/758====>test loss[0.16359374] | test accuracy[81.25000000%]\n",
            "TEST BATCH 565/758====>test loss[0.16385957] | test accuracy[68.75000000%]\n",
            "TEST BATCH 566/758====>test loss[0.16387539] | test accuracy[81.25000000%]\n",
            "TEST BATCH 567/758====>test loss[0.16399583] | test accuracy[75.00000000%]\n",
            "TEST BATCH 568/758====>test loss[0.16377808] | test accuracy[93.75000000%]\n",
            "TEST BATCH 569/758====>test loss[0.16351018] | test accuracy[100.00000000%]\n",
            "TEST BATCH 570/758====>test loss[0.16327204] | test accuracy[93.75000000%]\n",
            "TEST BATCH 571/758====>test loss[0.16330658] | test accuracy[81.25000000%]\n",
            "TEST BATCH 572/758====>test loss[0.16313755] | test accuracy[87.50000000%]\n",
            "TEST BATCH 573/758====>test loss[0.16322149] | test accuracy[75.00000000%]\n",
            "TEST BATCH 574/758====>test loss[0.16304474] | test accuracy[87.50000000%]\n",
            "TEST BATCH 575/758====>test loss[0.16304610] | test accuracy[87.50000000%]\n",
            "TEST BATCH 576/758====>test loss[0.16300484] | test accuracy[81.25000000%]\n",
            "TEST BATCH 577/758====>test loss[0.16299708] | test accuracy[81.25000000%]\n",
            "TEST BATCH 578/758====>test loss[0.16277266] | test accuracy[93.75000000%]\n",
            "TEST BATCH 579/758====>test loss[0.16269842] | test accuracy[87.50000000%]\n",
            "TEST BATCH 580/758====>test loss[0.16276776] | test accuracy[75.00000000%]\n",
            "TEST BATCH 581/758====>test loss[0.16322945] | test accuracy[50.00000000%]\n",
            "TEST BATCH 582/758====>test loss[0.16363342] | test accuracy[50.00000000%]\n",
            "TEST BATCH 583/758====>test loss[0.16388388] | test accuracy[62.50000000%]\n",
            "TEST BATCH 584/758====>test loss[0.16395827] | test accuracy[75.00000000%]\n",
            "TEST BATCH 585/758====>test loss[0.16415630] | test accuracy[68.75000000%]\n",
            "TEST BATCH 586/758====>test loss[0.16415131] | test accuracy[81.25000000%]\n",
            "TEST BATCH 587/758====>test loss[0.16435211] | test accuracy[62.50000000%]\n",
            "TEST BATCH 588/758====>test loss[0.16463668] | test accuracy[50.00000000%]\n",
            "TEST BATCH 589/758====>test loss[0.16479362] | test accuracy[68.75000000%]\n",
            "TEST BATCH 590/758====>test loss[0.16505809] | test accuracy[68.75000000%]\n",
            "TEST BATCH 591/758====>test loss[0.16512986] | test accuracy[75.00000000%]\n",
            "TEST BATCH 592/758====>test loss[0.16539226] | test accuracy[68.75000000%]\n",
            "TEST BATCH 593/758====>test loss[0.16590515] | test accuracy[50.00000000%]\n",
            "TEST BATCH 594/758====>test loss[0.16605959] | test accuracy[75.00000000%]\n",
            "TEST BATCH 595/758====>test loss[0.16631932] | test accuracy[56.25000000%]\n",
            "TEST BATCH 596/758====>test loss[0.16708755] | test accuracy[43.75000000%]\n",
            "TEST BATCH 597/758====>test loss[0.16741769] | test accuracy[56.25000000%]\n",
            "TEST BATCH 598/758====>test loss[0.16754034] | test accuracy[75.00000000%]\n",
            "TEST BATCH 599/758====>test loss[0.16764840] | test accuracy[68.75000000%]\n",
            "TEST BATCH 600/758====>test loss[0.16757671] | test accuracy[87.50000000%]\n",
            "TEST BATCH 601/758====>test loss[0.16777297] | test accuracy[68.75000000%]\n",
            "TEST BATCH 602/758====>test loss[0.16802496] | test accuracy[62.50000000%]\n",
            "TEST BATCH 603/758====>test loss[0.16839699] | test accuracy[43.75000000%]\n",
            "TEST BATCH 604/758====>test loss[0.16857025] | test accuracy[62.50000000%]\n",
            "TEST BATCH 605/758====>test loss[0.16853598] | test accuracy[81.25000000%]\n",
            "TEST BATCH 606/758====>test loss[0.16898532] | test accuracy[56.25000000%]\n",
            "TEST BATCH 607/758====>test loss[0.16903317] | test accuracy[75.00000000%]\n",
            "TEST BATCH 608/758====>test loss[0.16883654] | test accuracy[93.75000000%]\n",
            "TEST BATCH 609/758====>test loss[0.16890469] | test accuracy[81.25000000%]\n",
            "TEST BATCH 610/758====>test loss[0.16892023] | test accuracy[81.25000000%]\n",
            "TEST BATCH 611/758====>test loss[0.16909557] | test accuracy[68.75000000%]\n",
            "TEST BATCH 612/758====>test loss[0.16948382] | test accuracy[62.50000000%]\n",
            "TEST BATCH 613/758====>test loss[0.16952677] | test accuracy[75.00000000%]\n",
            "TEST BATCH 614/758====>test loss[0.16955717] | test accuracy[75.00000000%]\n",
            "TEST BATCH 615/758====>test loss[0.16976809] | test accuracy[56.25000000%]\n",
            "TEST BATCH 616/758====>test loss[0.17037379] | test accuracy[50.00000000%]\n",
            "TEST BATCH 617/758====>test loss[0.17084866] | test accuracy[50.00000000%]\n",
            "TEST BATCH 618/758====>test loss[0.17095498] | test accuracy[81.25000000%]\n",
            "TEST BATCH 619/758====>test loss[0.17120585] | test accuracy[56.25000000%]\n",
            "TEST BATCH 620/758====>test loss[0.17131829] | test accuracy[68.75000000%]\n",
            "TEST BATCH 621/758====>test loss[0.17170064] | test accuracy[50.00000000%]\n",
            "TEST BATCH 622/758====>test loss[0.17172360] | test accuracy[62.50000000%]\n",
            "TEST BATCH 623/758====>test loss[0.17176612] | test accuracy[68.75000000%]\n",
            "TEST BATCH 624/758====>test loss[0.17171826] | test accuracy[75.00000000%]\n",
            "TEST BATCH 625/758====>test loss[0.17212020] | test accuracy[43.75000000%]\n",
            "TEST BATCH 626/758====>test loss[0.17214172] | test accuracy[68.75000000%]\n",
            "TEST BATCH 627/758====>test loss[0.17207304] | test accuracy[81.25000000%]\n",
            "TEST BATCH 628/758====>test loss[0.17190215] | test accuracy[93.75000000%]\n",
            "TEST BATCH 629/758====>test loss[0.17203945] | test accuracy[68.75000000%]\n",
            "TEST BATCH 630/758====>test loss[0.17230357] | test accuracy[62.50000000%]\n",
            "TEST BATCH 631/758====>test loss[0.17237921] | test accuracy[81.25000000%]\n",
            "TEST BATCH 632/758====>test loss[0.17242522] | test accuracy[81.25000000%]\n",
            "TEST BATCH 633/758====>test loss[0.17265737] | test accuracy[68.75000000%]\n",
            "TEST BATCH 634/758====>test loss[0.17262622] | test accuracy[75.00000000%]\n",
            "TEST BATCH 635/758====>test loss[0.17247446] | test accuracy[93.75000000%]\n",
            "TEST BATCH 636/758====>test loss[0.17278710] | test accuracy[62.50000000%]\n",
            "TEST BATCH 637/758====>test loss[0.17279955] | test accuracy[81.25000000%]\n",
            "TEST BATCH 638/758====>test loss[0.17263680] | test accuracy[87.50000000%]\n",
            "TEST BATCH 639/758====>test loss[0.17271026] | test accuracy[68.75000000%]\n",
            "TEST BATCH 640/758====>test loss[0.17264948] | test accuracy[81.25000000%]\n",
            "TEST BATCH 641/758====>test loss[0.17270076] | test accuracy[68.75000000%]\n",
            "TEST BATCH 642/758====>test loss[0.17282206] | test accuracy[75.00000000%]\n",
            "TEST BATCH 643/758====>test loss[0.17271583] | test accuracy[81.25000000%]\n",
            "TEST BATCH 644/758====>test loss[0.17257714] | test accuracy[81.25000000%]\n",
            "TEST BATCH 645/758====>test loss[0.17287504] | test accuracy[62.50000000%]\n",
            "TEST BATCH 646/758====>test loss[0.17326254] | test accuracy[43.75000000%]\n",
            "TEST BATCH 647/758====>test loss[0.17349310] | test accuracy[62.50000000%]\n",
            "TEST BATCH 648/758====>test loss[0.17338408] | test accuracy[87.50000000%]\n",
            "TEST BATCH 649/758====>test loss[0.17360441] | test accuracy[62.50000000%]\n",
            "TEST BATCH 650/758====>test loss[0.17357751] | test accuracy[81.25000000%]\n",
            "TEST BATCH 651/758====>test loss[0.17346794] | test accuracy[87.50000000%]\n",
            "TEST BATCH 652/758====>test loss[0.17360769] | test accuracy[75.00000000%]\n",
            "TEST BATCH 653/758====>test loss[0.17360838] | test accuracy[81.25000000%]\n",
            "TEST BATCH 654/758====>test loss[0.17387088] | test accuracy[62.50000000%]\n",
            "TEST BATCH 655/758====>test loss[0.17365074] | test accuracy[93.75000000%]\n",
            "TEST BATCH 656/758====>test loss[0.17349761] | test accuracy[87.50000000%]\n",
            "TEST BATCH 657/758====>test loss[0.17352234] | test accuracy[81.25000000%]\n",
            "TEST BATCH 658/758====>test loss[0.17357694] | test accuracy[75.00000000%]\n",
            "TEST BATCH 659/758====>test loss[0.17380428] | test accuracy[68.75000000%]\n",
            "TEST BATCH 660/758====>test loss[0.17403937] | test accuracy[62.50000000%]\n",
            "TEST BATCH 661/758====>test loss[0.17416803] | test accuracy[75.00000000%]\n",
            "TEST BATCH 662/758====>test loss[0.17423854] | test accuracy[68.75000000%]\n",
            "TEST BATCH 663/758====>test loss[0.17430458] | test accuracy[68.75000000%]\n",
            "TEST BATCH 664/758====>test loss[0.17435890] | test accuracy[75.00000000%]\n",
            "TEST BATCH 665/758====>test loss[0.17431414] | test accuracy[81.25000000%]\n",
            "TEST BATCH 666/758====>test loss[0.17434328] | test accuracy[81.25000000%]\n",
            "TEST BATCH 667/758====>test loss[0.17429936] | test accuracy[75.00000000%]\n",
            "TEST BATCH 668/758====>test loss[0.17427062] | test accuracy[81.25000000%]\n",
            "TEST BATCH 669/758====>test loss[0.17402217] | test accuracy[100.00000000%]\n",
            "TEST BATCH 670/758====>test loss[0.17403706] | test accuracy[75.00000000%]\n",
            "TEST BATCH 671/758====>test loss[0.17416704] | test accuracy[62.50000000%]\n",
            "TEST BATCH 672/758====>test loss[0.17391992] | test accuracy[100.00000000%]\n",
            "TEST BATCH 673/758====>test loss[0.17387626] | test accuracy[87.50000000%]\n",
            "TEST BATCH 674/758====>test loss[0.17375583] | test accuracy[87.50000000%]\n",
            "TEST BATCH 675/758====>test loss[0.17368571] | test accuracy[87.50000000%]\n",
            "TEST BATCH 676/758====>test loss[0.17344056] | test accuracy[100.00000000%]\n",
            "TEST BATCH 677/758====>test loss[0.17350938] | test accuracy[62.50000000%]\n",
            "TEST BATCH 678/758====>test loss[0.17379378] | test accuracy[56.25000000%]\n",
            "TEST BATCH 679/758====>test loss[0.17363623] | test accuracy[87.50000000%]\n",
            "TEST BATCH 680/758====>test loss[0.17436136] | test accuracy[31.25000000%]\n",
            "TEST BATCH 681/758====>test loss[0.17421455] | test accuracy[93.75000000%]\n",
            "TEST BATCH 682/758====>test loss[0.17431199] | test accuracy[68.75000000%]\n",
            "TEST BATCH 683/758====>test loss[0.17410168] | test accuracy[93.75000000%]\n",
            "TEST BATCH 684/758====>test loss[0.17395700] | test accuracy[87.50000000%]\n",
            "TEST BATCH 685/758====>test loss[0.17389787] | test accuracy[75.00000000%]\n",
            "TEST BATCH 686/758====>test loss[0.17385271] | test accuracy[87.50000000%]\n",
            "TEST BATCH 687/758====>test loss[0.17396242] | test accuracy[75.00000000%]\n",
            "TEST BATCH 688/758====>test loss[0.17393945] | test accuracy[81.25000000%]\n",
            "TEST BATCH 689/758====>test loss[0.17376970] | test accuracy[87.50000000%]\n",
            "TEST BATCH 690/758====>test loss[0.17396298] | test accuracy[68.75000000%]\n",
            "TEST BATCH 691/758====>test loss[0.17421689] | test accuracy[62.50000000%]\n",
            "TEST BATCH 692/758====>test loss[0.17435832] | test accuracy[62.50000000%]\n",
            "TEST BATCH 693/758====>test loss[0.17455581] | test accuracy[62.50000000%]\n",
            "TEST BATCH 694/758====>test loss[0.17468523] | test accuracy[62.50000000%]\n",
            "TEST BATCH 695/758====>test loss[0.17478490] | test accuracy[68.75000000%]\n",
            "TEST BATCH 696/758====>test loss[0.17481829] | test accuracy[68.75000000%]\n",
            "TEST BATCH 697/758====>test loss[0.17479168] | test accuracy[81.25000000%]\n",
            "TEST BATCH 698/758====>test loss[0.17475986] | test accuracy[81.25000000%]\n",
            "TEST BATCH 699/758====>test loss[0.17482130] | test accuracy[68.75000000%]\n",
            "TEST BATCH 700/758====>test loss[0.17465913] | test accuracy[93.75000000%]\n",
            "TEST BATCH 701/758====>test loss[0.17464426] | test accuracy[87.50000000%]\n",
            "TEST BATCH 702/758====>test loss[0.17450803] | test accuracy[93.75000000%]\n",
            "TEST BATCH 703/758====>test loss[0.17432270] | test accuracy[93.75000000%]\n",
            "TEST BATCH 704/758====>test loss[0.17409960] | test accuracy[100.00000000%]\n",
            "TEST BATCH 705/758====>test loss[0.17400432] | test accuracy[81.25000000%]\n",
            "TEST BATCH 706/758====>test loss[0.17389924] | test accuracy[87.50000000%]\n",
            "TEST BATCH 707/758====>test loss[0.17372373] | test accuracy[87.50000000%]\n",
            "TEST BATCH 708/758====>test loss[0.17349818] | test accuracy[100.00000000%]\n",
            "TEST BATCH 709/758====>test loss[0.17326112] | test accuracy[100.00000000%]\n",
            "TEST BATCH 710/758====>test loss[0.17341611] | test accuracy[68.75000000%]\n",
            "TEST BATCH 711/758====>test loss[0.17330807] | test accuracy[81.25000000%]\n",
            "TEST BATCH 712/758====>test loss[0.17334437] | test accuracy[75.00000000%]\n",
            "TEST BATCH 713/758====>test loss[0.17325715] | test accuracy[81.25000000%]\n",
            "TEST BATCH 714/758====>test loss[0.17317685] | test accuracy[87.50000000%]\n",
            "TEST BATCH 715/758====>test loss[0.17295551] | test accuracy[100.00000000%]\n",
            "TEST BATCH 716/758====>test loss[0.17296477] | test accuracy[75.00000000%]\n",
            "TEST BATCH 717/758====>test loss[0.17286770] | test accuracy[87.50000000%]\n",
            "TEST BATCH 718/758====>test loss[0.17285423] | test accuracy[81.25000000%]\n",
            "TEST BATCH 719/758====>test loss[0.17280495] | test accuracy[87.50000000%]\n",
            "TEST BATCH 720/758====>test loss[0.17266721] | test accuracy[93.75000000%]\n",
            "TEST BATCH 721/758====>test loss[0.17274594] | test accuracy[56.25000000%]\n",
            "TEST BATCH 722/758====>test loss[0.17274710] | test accuracy[75.00000000%]\n",
            "TEST BATCH 723/758====>test loss[0.17298457] | test accuracy[68.75000000%]\n",
            "TEST BATCH 724/758====>test loss[0.17285716] | test accuracy[93.75000000%]\n",
            "TEST BATCH 725/758====>test loss[0.17291570] | test accuracy[75.00000000%]\n",
            "TEST BATCH 726/758====>test loss[0.17333076] | test accuracy[43.75000000%]\n",
            "TEST BATCH 727/758====>test loss[0.17313963] | test accuracy[93.75000000%]\n",
            "TEST BATCH 728/758====>test loss[0.17315323] | test accuracy[81.25000000%]\n",
            "TEST BATCH 729/758====>test loss[0.17327349] | test accuracy[75.00000000%]\n",
            "TEST BATCH 730/758====>test loss[0.17306636] | test accuracy[93.75000000%]\n",
            "TEST BATCH 731/758====>test loss[0.17286198] | test accuracy[93.75000000%]\n",
            "TEST BATCH 732/758====>test loss[0.17283435] | test accuracy[81.25000000%]\n",
            "TEST BATCH 733/758====>test loss[0.17261663] | test accuracy[100.00000000%]\n",
            "TEST BATCH 734/758====>test loss[0.17240875] | test accuracy[100.00000000%]\n",
            "TEST BATCH 735/758====>test loss[0.17220873] | test accuracy[100.00000000%]\n",
            "TEST BATCH 736/758====>test loss[0.17206836] | test accuracy[93.75000000%]\n",
            "TEST BATCH 737/758====>test loss[0.17185507] | test accuracy[100.00000000%]\n",
            "TEST BATCH 738/758====>test loss[0.17193461] | test accuracy[68.75000000%]\n",
            "TEST BATCH 739/758====>test loss[0.17173866] | test accuracy[93.75000000%]\n",
            "TEST BATCH 740/758====>test loss[0.17168196] | test accuracy[87.50000000%]\n",
            "TEST BATCH 741/758====>test loss[0.17167814] | test accuracy[81.25000000%]\n",
            "TEST BATCH 742/758====>test loss[0.17162969] | test accuracy[81.25000000%]\n",
            "TEST BATCH 743/758====>test loss[0.17176425] | test accuracy[75.00000000%]\n",
            "TEST BATCH 744/758====>test loss[0.17191832] | test accuracy[56.25000000%]\n",
            "TEST BATCH 745/758====>test loss[0.17202522] | test accuracy[68.75000000%]\n",
            "TEST BATCH 746/758====>test loss[0.17204033] | test accuracy[75.00000000%]\n",
            "TEST BATCH 747/758====>test loss[0.17209862] | test accuracy[56.25000000%]\n",
            "TEST BATCH 748/758====>test loss[0.17191701] | test accuracy[93.75000000%]\n",
            "TEST BATCH 749/758====>test loss[0.17198702] | test accuracy[75.00000000%]\n",
            "TEST BATCH 750/758====>test loss[0.17201598] | test accuracy[75.00000000%]\n",
            "TEST BATCH 751/758====>test loss[0.17199387] | test accuracy[81.25000000%]\n",
            "TEST BATCH 752/758====>test loss[0.17190620] | test accuracy[81.25000000%]\n",
            "TEST BATCH 753/758====>test loss[0.17189718] | test accuracy[68.75000000%]\n",
            "TEST BATCH 754/758====>test loss[0.17186755] | test accuracy[75.00000000%]\n",
            "TEST BATCH 755/758====>test loss[0.17198976] | test accuracy[68.75000000%]\n",
            "TEST BATCH 756/758====>test loss[0.17177074] | test accuracy[100.00000000%]\n",
            "TEST BATCH 757/758====>test loss[0.17198856] | test accuracy[56.25000000%]\n",
            "TEST BATCH 758/758====>test loss[0.17218246] | test accuracy[31.25000000%]\n",
            "AVG Accuracy =  78.56200527704486\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sentence_model_up.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}